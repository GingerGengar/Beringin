%Type of Document
\documentclass[a4paper, 12pt]{report}

%Load Pre-ambles
\usepackage{../Environment/Packages}
\usepackage{../Environment/Conventions}
\usepackage{../Environment/Hyahoos}

\begin{document}

\begin{center}
\chapter{Dynamical Systems: Eigenvalues and Eigenvectors}
\begin{comment}
\end{comment}
Let A represent a $n \times n$ matrix (a matrix with n rows and n columns), $x$ represent a column vector of $n$ variables and $x'$ represent the derivative of the column vector $x$. The system below is known as a dynamical system:
$$x' = Ax$$
\\Consider the dynamical system $x' = kx$ wherein k is some arbitrary constant. Therefore,
$$\f{dx}{dt} = kx$$
$$dt = \f{1}{kx}dx$$
$$\int dt = \int \f{1}{kx}dx$$
$$t = \f{1}{k}\ln{x}+ C$$
$$\ln{x} = kt + C$$
$$x = Ce^{kt}$$
Wherein C is a constant determined by the initial conditions.
%Seperator
%Seperator 
%Seperator
%Seperator
%Seperator
\section{Non-Repeated Real Eigenvalues of n $\times$ n Case}
\begin{comment}
\end{comment}
The previous working gives the conjecture that the general solution set $x(t)$ to the dynamical system $x' = Ax$ is the linear combination of exponential functions analogous to the example shown above. Consider the possibility that one solution to the dynamical system takes the form below:
$$x(t) = \b{v_i}e^{\la_i t}$$
\\wherein $\b{v_i}$ represents a vector and $\la_i$ represents a constant. By taking derivative of the solution, 
$$x'(t) = \la_i\b{v_i}e^{\la_i t}$$
$$Ax(t) = A\b{v_i}e^{\la_i t}$$
\\By considering that $x(t)$ represents a solution to the dynamical system, $\dst{x' = Ax}$
$$\la_i\b{v_i}e^{\la_i t} = A\b{v_i}e^{\la_i t}$$
Since $e^{\la_i t} \neq 0$ for all values of $t$,
$$A\b{v_i} = \la_i\b{v_i}$$
\\This is a familiar equation for eigenvalues and eigenvectors. This shows that each eigenvalue-eigenvector pairs of the matrix $A$ represents a solution set. Therefore, the general solution set is:
$$x(t) = span[\b{v_1}e^{\a_1 t}, \b{v_2}e^{\a_2 t}, \dots \b{v_n}e^{\a_n t}]$$
$$x(t) = \sum_{i = 1}^{n} \l[c_i\b{v_i}e^{\la_i t}\r]$$
wherein $c_i$ are constants determined by the initial value of the problem. 
%Seperator
%Seperator
%Seperator
%Seperator
%Seperator
\section{Non-Repeated Complex Eigenvalues of 2 $\times$ 2 Case}
\begin{comment}
\end{comment}
Consider the special case wherein the matrix A is a $2\times2$ matrix and that the eigenvalues are complex, by conjecture,
$$x(t) = c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = k_1Re[\b{v_1}e^{\la_1 t}] + k_2Im[\b{v_1}e^{\la_1 t}]$$
\\wherein $c_1$ and $c_2$ are complex values meanwhile $k_1$ and $k_2$ are real values. There must always be some choice of complex values $c_1$ and $c_2$ such that the expression above is true. The proof is shown below,
\\~\\Let 
$$\b{v_1} = \b{v_r} + i\b{v_i}\qquad \la_1 = a + bi$$
$$x(t) = (\b{v_r} + i\b{v_i})e^{(a+bi)t}$$
$$x(t) = e^{at}(\b{v_r} + i\b{v_i})[\cos{(bt)} + i\sin{(bt)}]$$
$$x(t) = e^{at}[\b{v_r}\cos{(bt)} + i\b{v_r}\sin{(bt)} + i\b{v_i}\cos{(bt)} - \b{v_i}\sin{(bt)}]$$
$$x(t) = e^{at}[\b{v_r}\cos{(bt)} - \b{v_i}\sin{(bt)}]+ ie^{at}[\b{v_r}\sin{(bt)} + \b{v_i}\cos{(bt)}]$$
$$Re[\b{v_1}e^{\la_1 t}] = e^{at}[\b{v_r}\cos{(bt)} - \b{v_i}\sin{(bt)}]$$
$$Im[\b{v_1}e^{\la_1 t}] = e^{at}[\b{v_r}\sin{(bt)} + \b{v_i}\cos{(bt)}]$$
$$LHS = k_1Re[\b{v_1}e^{\la_1 t}] + k_2Im[\b{v_1}e^{\la_1 t}]$$
$$LHS = k_1e^{at}[\b{v_r}\cos{(bt)} - \b{v_i}\sin{(bt)}] + k_2e^{at}[\b{v_r}\sin{(bt)} + \b{v_i}\cos{(bt)}]$$
$$LHS = e^{at}[k_1\b{v_r}\cos{(bt)} - k_1\b{v_i}\sin{(bt)} + k_2\b{v_r}\sin{(bt)} + k_2\b{v_i}\cos{(bt)}]$$
$$LHS = e^{at}\{[k_1\b{v_r}+ k_2\b{v_i}]\cos{(bt)}  + [k_2\b{v_r}- k_1\b{v_i}]\sin{(bt)}\}$$
$$LHS = e^{at}[k_1\b{v_r}+ k_2\b{v_i}]\cos{(bt)}  + e^{at}[k_2\b{v_r}- k_1\b{v_i}]\sin{(bt)}$$
\\It is important to note that eigenvalues and their corresponding eigenvectors occur in conjugate pairs. Therefore, if $\la_1 = a+bi$, then $\la_2 = \la_1^\ast = a - bi$ and if the eigenvector $\b{v_1} = \b{v_r} + i\b{v_i}$, then $\b{v_2} =\b{v_1}^\ast= \b{v_r} - i\b{v_i}$.
\\~\\Let
$$c_1 = f_1 + g_1i\qquad c_2 = f_2 + g_2i$$
$$c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = (f_1 + g_1i)(\b{v_r} + i\b{v_i})e^{(a+bi)t} + (f_2 + g_2i)(\b{v_r} - i\b{v_i})e^{(a-bi)t}$$
\\For ease of notation,
$$A(t) = (f_1 + g_1i)(\b{v_r} + i\b{v_i})e^{(a+bi)t}\qquad B(t) = (f_2 + g_2i)(\b{v_r} - i\b{v_i})e^{(a-bi)t}$$
%Restatement of the original LHS of the equation
$$c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = A(t) + B(t)$$
%Beginning of the script for the "A" components
$$A(t) = e^{at}(f_1 + g_1i)(\b{v_r} + i\b{v_i})\l[\cos{(bt)} + i \sin{(bt)}\r]$$
$$A(t) = e^{at}(f_1\b{v_r} + if_1\b{v_i} + ig_1\b{v_r} - g_1\b{v_i})\l[\cos{(bt)} + i \sin{(bt)}\r]$$
$$A(t) = e^{at}[f_1\b{v_r} - g_1\b{v_i}+ i(f_1\b{v_i} + g_1\b{v_r})]\l[\cos{(bt)} + i \sin{(bt)}\r]$$
$$A(t) = e^{at}[(f_1\b{v_r} - g_1\b{v_i})\cos{(bt)} + i(f_1\b{v_i} + g_1\b{v_r})\cos{(bt)} + i(f_1\b{v_r} - g_1\b{v_i})\sin{(bt)} - (f_1\b{v_i} + g_1\b{v_r})\sin{(bt)}]$$
%Beginning of the script for the "B" components
$$B(t) = (f_2 + g_2i)(\b{v_r} - i\b{v_i})e^{(a-bi)t}$$
$$B(t) = e^{at}(f_2\b{v_r} - if_2\b{v_i} + ig_2\b{v_r} + g_2\b{v_i})\l[\cos{(-bt)} + i\sin{(-bt)}\r]$$
$$B(t) = e^{at}[(f_2\b{v_r} + g_2\b{v_i}) + i(g_2\b{v_r} - f_2\b{v_i})]\l[\cos{(bt)} - i\sin{(bt)}\r]$$
$$B(t) = e^{at}[(f_2\b{v_r} + g_2\b{v_i})\cos{(bt)} + i(g_2\b{v_r} - f_2\b{v_i})\cos{(bt)} + i(-f_2\b{v_r} - g_2\b{v_i})\sin{(bt)} + (g_2\b{v_r} - f_2\b{v_i})\sin{(bt)}]$$
%End of the script for the "B" components
$$c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = Re[A(t)] + Re[B(t)] + i\{Im[A(t)] + Im[B(t)]\}$$
$$0 = Im[A(t)] + Im[B(t)]$$
$$0 = (f_1\b{v_i} + g_1\b{v_r})\cos{(bt)} + (f_1\b{v_r} - g_1\b{v_i})\sin{(bt)} + (g_2\b{v_r} - f_2\b{v_i})\cos{(bt)} - (f_2\b{v_r} + g_2\b{v_i})\sin{(bt)}$$
$$0 = (f_1\b{v_i} + g_1\b{v_r} + g_2\b{v_r} - f_2\b{v_i})\cos{(bt)} + (f_1\b{v_r} - g_1\b{v_i} -f_2\b{v_r} - g_2\b{v_i})\sin{bt}$$
$$0 = [(g_1 + g_2)\b{v_r} + (f_1 - f_2)\b{v_i}]\cos{(bt)} + [(f_1 - f_2)\b{v_r} - (g_1 + g_2)\b{v_i}]\sin{(bt)}$$
\\For as long as the condition below is met, the imaginary component of $A(t) + B(t)$ is negligible.
$$g_1 = -g_2 \qquad f_1 = f_2$$
$$c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = Re[A(t)] + Re[B(t)] $$
\begin{equation*}
\begin{split}c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t}  = &e^{at}(f_1\b{v_r} - g_1\b{v_i})\cos{(bt)} - (f_1\b{v_i} + g_1\b{v_r})\sin{(bt)}  \\ &+ (f_2\b{v_r} + g_2\b{v_i})\cos{(bt)} + (g_2\b{v_r} - f_2\b{v_i})\sin{(bt)}
\end{split}
\end{equation*}
$$c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = e^{at}(f_1\b{v_r} - g_1\b{v_i} + f_2\b{v_r} + g_2\b{v_i})\cos{(bt)} + (g_2\b{v_r} - f_2\b{v_i}-f_1\b{v_i} - g_1\b{v_r})\sin{(bt)} $$
$$c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = e^{at}[(f_1 + f_2)\b{v_r} +(g_2- g_1)\b{v_i}]\cos{(bt)} + [(g_2 - g_1\b)\b{v_r} - (f_1 + f_2)\b{v_i}]\sin{(bt)} $$
$$RHS = c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t}$$
$$RHS = e^{at}[(f_1 + f_2)\b{v_r} +(g_2- g_1)\b{v_i}]\cos{(bt)} + e^{at}[(g_2 - g_1)\b{v_r} - (f_1 + f_2)\b{v_i}]\sin{(bt)}$$
$$LHS = e^{at}[k_1\b{v_r}+ k_2\b{v_i}]\cos{(bt)}  + e^{at}[k_2\b{v_r}- k_1\b{v_i}]\sin{(bt)}$$
\\If the conditions below are met, therefore $LHS = RHS$ and the statement $\dst{x(t) = c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = k_1Re[\b{v_1}e^{\la_1 t}] + k_2Im[\b{v_1}e^{\la_1 t}]}$ is true. 
$$g_1 + g_2 =0 \qquad f_1 + f_2 - k_1 = 0 \qquad f_1 - f_2 = 0 \qquad g_2 - g_1 - k_2 = 0$$
\\The corresponding augmented matrix of the following conditions is
\begin{equation*}
\begin{split}
\begin{matrix}f_1 & f_2 & g_1 & g_2 & k_1 & k_2 & C \end{matrix} \\ \begin{pmatrix}1 & 1 & 0 &0 &-1 &0 &0 \\1 &-1 &0 &0 &0 &0 &0 \\ 0&0 &1 &-1 &0 &1 &0  \\ 0&0 &1 &1 &0 &0 &0 \end{pmatrix}
\end{split}
\end{equation*}
\\The row-reduced echelon form of the corresponding augmented matrix is
$$\begin{matrix} f_1 & f_2 & g_1 & g_2 & k_1 & k_2 & C \end{matrix}$$
$$\begin{pmatrix}1 &0 &0 &0 &-\f{1}{2} &0 &0 \\ 0& 1&0 &0 &-\f{1}{2} &0 &0 \\0 &0 &1 &0 &0 &\f{1}{2} & 0\\0 &0 &0 &1 &0 &-\f{1}{2} &0 \end{pmatrix}$$
\\The row-reduced echelon form is unique and is consistent, therefore the system has a consistent solution. This proves that for some special choice of $c_1$ and $c_2$, the expression below is correct.
$$x(t) = c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = k_1Re[\b{v_1}e^{\la_1 t}] + k_2Im[\b{v_1}e^{\la_1 t}]$$
A restatement of the general real solution set is:
$$x(t)=k_1e^{at}[\b{v_r}\cos{(bt)} - \b{v_i}\sin{(bt)}] + k_2e^{at}[\b{v_r}\sin{(bt)} + \b{v_i}\cos{(bt)}]$$
The solution set for all real numbers could be better expressed as a matrix multiplication
$$x(t) = e^{at}\begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix} \begin{pmatrix} \cos{(bt)}& -\sin{(bt)} \\ \sin{(bt)}& \cos{(bt)} \end{pmatrix} \begin{pmatrix} k_2 \\ k_1\end{pmatrix}$$
\\The real and imaginary components of the eigenvector $v_1$ form a linearly independent set. Therfore, the matrix $\dst{\begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}}$ must be invertible. Through the invertible matrix theorem, the matrix $\dst{\begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}}$ must have a suitable inverse. 
 $$x(t) = e^{at}\begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix} \begin{pmatrix} \cos{(bt)}& -\sin{(bt)} \\  \sin{(bt)}& \cos{(bt)} \end{pmatrix} \begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}^{-1}  \begin{pmatrix}  x_2 \\ x_1\end{pmatrix}$$
 $$x(t) = e^{at}\begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix} \begin{pmatrix} \cos{(bt)}& -\sin{(bt)} \\  \sin{(bt)}& \cos{(bt)} \end{pmatrix} \begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}^{-1}  x_0$$
$$\begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}^{-1}x(t) = e^{at} \begin{pmatrix} \cos{(bt)}& -\sin{(bt)} \\ \sin{(bt)}& \cos{(bt)} \end{pmatrix} \begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}^{-1}  x_0$$
By considering the substitution $\dst{y = \begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}^{-1}x(t)}$ and $\dst{y_0 = \begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}^{-1}  x_0}$,
$$y = e^{at} \begin{pmatrix} \cos{(bt)}& -\sin{(bt)} \\ \sin{(bt)}& \cos{(bt)} \end{pmatrix} y_0$$
\\wherein $e^{at}$ represents a scaling transformation and $\dst{\begin{pmatrix} \cos{(bt)}& -\sin{(bt)} \\ \sin{(bt)}& \cos{(bt)} \end{pmatrix}}$ represents a rotation. Therefore, for a suitable substitution, the general real solution set of the dynamical system $\dst{x' = Ax}$ will form a rotation with a scaling component. The rotation is sometimes known as the "hidden rotation". Some possibilities of the solution set may be ellipses, circles, and spirals. 
%Seperator
%Seperator
%Seperator
%Seperator
%Seperator
\section{Non-Repeated Complex Eigenvalues of 3 $\times$ 3 Case}
\begin{comment}
\end{comment}
Consider the case wherein $n = 3$
$$x(t) = \sum_{i=1}^{3}\l[c_i\b{v_i}e^{\la_i t}\r]$$
$$x(t) = c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} + c_3\b{v_3}e^{\la_3 t}$$
\\Complex eigenvalues occure in conjugate pairs. When A is a $3 \times 3$ matrix, $2$ of the eigenvalues will be complex conjugate pairs and the third one will be a real value. Therefore, two of the eigenvectors must be complex vectors with the third eigenvector being a real vector. Therefore, through the similar argument and proof written above, 
$$x(t) = k_1Re\l[\b{v_1}e^{\la_1 t}\r] + k_2Re\l[\b{v_1}e^{\la_1 t}\r] + k_3\b{v_3}e^{\la_3 t}$$
$$x(t)=k_1e^{at}[\b{v_r}\cos{(bt)} - \b{v_i}\sin{(bt)}] + k_2e^{at}[\b{v_r}\sin{(bt)} + \b{v_i}\cos{(bt)}] + k_3\b{v_3}e^{\la_3 t}$$
\\The following solution set could be factorised as matrix multiplications
$$x(t) = e^{at} \begin{pmatrix} \b{v_i}&\b{v_r} &\b{v_3} \end{pmatrix} \begin{pmatrix}\cos{(bt)} &-\sin{(bt)} &0\\\sin{(bt)}&\cos{(bt)} & 0\\0& 0& e^{(\la_3 - a)t}\end{pmatrix} \begin{pmatrix} k_2 \\k_1 \\ k_3 \end{pmatrix}$$
The vectors $\b{v_i},\b{v_r},\b{v_3}$ form a linearly independent set, therefore, the matrix $\dst{\begin{pmatrix} \b{v_i}&\b{v_r} &\b{v_3} \end{pmatrix}}$ is invertible and its inverse must exist.
\\Let $\dst{y_0 = \begin{pmatrix} k_2\\k_1 \\k_3 \end{pmatrix}}$ 
$$\begin{pmatrix} \b{v_i}&\b{v_r} &\b{v_3} \end{pmatrix} ^{-1 }x(t) = e^{at} \begin{pmatrix}\cos{(bt)} &-\sin{(bt)} &0\\\sin{(bt)}&\cos{(bt)} & 0\\0& 0& e^{(\la_3 - a)t}\end{pmatrix} y_0$$
\\Let $\dst{y(t) = \begin{pmatrix} \b{v_i}&\b{v_r} &\b{v_3} \end{pmatrix} ^{-1 }x(t)}$
$$y(t) = e^{at} \begin{pmatrix}\cos{(bt)} &-\sin{(bt)} &0\\\sin{(bt)}&\cos{(bt)} & 0\\0& 0& e^{(\la_3 - a)t}\end{pmatrix} y_0$$
\\$y_0$ is dependent on the system's initial conditions. This shows that for some suitable substitution, the general solution set forms a helix. The geometrical implication of the solution set is a spiral around the z-axis while it is moving away from the xy plane. The substitution back into the conventional axis $x_1,x_2,x_3$ could be considered as a transformation that "distorts" the helix. 
%Seperator
%Seperator
%Seperator
%Seperator
%Seperator
\section{Repeated Eigenvalues}
\begin{comment}
\end{comment}
Given the matrix $A$ in the system $x' = Ax$ is a matrix with repeated eigenvalues with multiplicity k, a reasonable conjecture is the solution to the system is similar in form to the repeated roots case in the linear differential equation. By conjecture,
$$x(t) = \sum_{i = 0}^{k - 1}\l[\b{v_i} t^{k - 1 - i}e^{\la t}\r]$$
$$x'(t) = \sum_{i = 0}^{k - 1}\l[\b{v_i} \f{d}{dt}\l[t^{k - 1 - i}e^{\la t}\r] \r]$$
$$\f{d}{dt}\l[t^{k - 1 - i}e^{\la t}\r] = (k - 1 - i)t^{k - 2 - i}e^{\la t} + \la t^{k - 1 - i}e^{\la t} $$
$$x'(t) = \sum_{i = 0}^{k - 1}\l[(k - 1 - i)t^{k - 2 - i}\b{v_i}e^{\la t} + \la t^{k - 1 - i}\b{v_i}e^{\la t} \r]$$
Remembering $x'(t) = Ax(t)$,
$$\sum_{i = 0}^{k - 1}\l[A\b{v_i} t^{k - 1 - i}e^{\la t}\r] = \sum_{i = 0}^{k - 1}\l[ (k - 1 - i)t^{k - 2 - i}\b{v_i}e^{\la t} + \la t^{k - 1 - i}\b{v_i}e^{\la t} \r]$$
Considering that $e^{\la t} \neq 0$, therefore, 
$$\sum_{i = 0}^{k - 1}\l[A\b{v_i} t^{k - 1 - i}\r] = \sum_{i = 0}^{k - 1}\l[ \la t^{k - 1 - i}\b{v_i} + (k - 1 - i)t^{k - 2 - i}\b{v_i}\r]$$
\\For the $0^{th}$ element,
$$A\b{v_0}t^{k - 1} = \la t^{k - 1}\b{v_0}$$
Considering that $t^{k - 1} \neq 0$ for as long as $t \neq 0$,
$$A\b{v_0} = \la \b{v_0}$$
For the $\a^{th}$ element, 
$$A\b{v_\a} t^{k - 1 - \a} = \la t^{k - 1 - \a}\b{v_\a} +  \l[k - 1 - (\a - 1)\r]t^{k - 2 - (\a - 1)}\b{v_{\a - 1}}$$
$$A\b{v_\a} t^{k - 1 - \a} = \la t^{k - 1 - \a}\b{v_\a} +  \l[k - \a \r]t^{k - 1 - \a}\b{v_{\a - 1}}$$
For as long as $t\neq 0$,  $t^{k - 1- \a}\neq 0$. Therefore, 
$$A\b{v_\a} = \la \b{v_\a} +  \l[k - \a \r]\b{v_{\a - 1}}$$
$$\f{1}{\l[k - \a \r]} (A - \la I)\b{v_\a} = \b{v_{\a - 1}}$$
\\By applying definition recursively,
$$\f{1}{\dst{\prod_{i = 0}^{j - 1}\l[k - i \r]}} (A - \la I)^j \b{v_\a} = \b{v_{\a - j}}$$
For when $j = \a$,
$$\f{1}{\dst{\prod_{i = 0}^{\a - 1}\l[k - i \r]}} (A - \la I)^\a \b{v_\a} = \b{v_{0}}$$
%Seperator
%Seperator
%Seperator
%Seperator
%Seperator
\section{Simple First Order Non-Homogenous System}
\begin{comment}
\end{comment}
Suppose, for a non-homogeneous dynamical system, $x' = Ax + k$. The non-homogenous dynamical system could be reduced to a homogenous dynamical system, $y' = Ay$ by an appropriate substitution shown below:  
$$y_1 = x_1 + c_1 \qquad y_2 = x_2 + c_2 \qquad \dots \qquad y_n = x_n + c_n $$
\\wherein $c_1, c_2, c_3 \dots c_n$ are constants
$$y_1' = x_1' \qquad y_2' = x_2' \qquad \dots \qquad y_n' = x_n'$$
\\Let the columns of matrix $A$ be denoted as $a_1, a_2, a_3,\dots a_n$
$$A = \begin{bmatrix} \b{a_1} & \b{a_2} &\dots & \b{a_n} \end{bmatrix}$$
$$Ay = \begin{bmatrix} \b{a_1} & \b{a_2} &\dots & \b{a_n} \end{bmatrix} \begin{bmatrix}y_1 \\ y_2 \\ \vdots \\ y_n \end{bmatrix}$$
$$Ay = \sum_{i = 1} ^ {n} \l[\b{a_i}y_i\r]$$
$$Ay = \sum_{i = 1} ^ {n} \l[\b{a_i}(x_i +c_i)\r]$$
$$Ay = \sum_{i = 1} ^ {n} \l[\b{a_i}x_i + \b{a_i}c_i\r]$$
$$Ay = \sum_{i = 1} ^ {n} \l[\b{a_i}x_i\r] + \sum_{i = 1} ^ {n} \l[\b{a_i}c_i\r]$$
$$Ax + k= \begin{bmatrix} \b{a_1} & \b{a_2} &\dots & \b{a_n} \end{bmatrix} \begin{bmatrix}x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix} + \begin{bmatrix} k_1 \\k_2 \\\vdots \\k_n\end{bmatrix}$$
$$Ax + k = \sum_{i = 1}^{n} \l[\b{a_i}x_i\r] + k$$
$$Ay = Ax + k$$
$$\sum_{i = 1} ^ {n} \l[\b{a_i}x_i\r] + \sum_{i = 1} ^ {n} \l[\b{a_i}c_i\r] = \sum_{i = 1}^{n} \l[\b{a_i}x_i\r] + k$$
$$\sum_{i = 1} ^ {n} \l[\b{a_i}c_i\r] =  k$$
The system above is equivalent to an augmented matrix whose first column until nth column is the columns of the matrix A and its last column is the column vector k. Therefore, the augmented matrix is written below:
$$\begin{matrix}c_1 & c_2 & \dots & c_n& K \end{matrix}$$
$$\begin{bmatrix} \b{a_1} & \b{a_2} & \dots &\b{a_n} &k \end{bmatrix}$$
\\The solution to the augmented matrix will be the values for the constants $c_1,c_2,\dots,c_n$ that would be used in the substitution process in transforming the non-homogenous dynamical system into a homogenous dynamical system. The augmented matrix above would only have a solution for all k in $\mathbb{R}^{n}$ if the matrix A is invertible. If the matrix A is non-invertible , then k must be in $col[A]$, otherwise, then the augmented system forms an inconsistent system. In otherwords, a substitution with the above methods may not exist for an aribtrary choice of $n\times n$ matrix A and arbitrary column vector k. 
%Seperator
%Seperator
%Seperator
%Seperator
%Seperator
\section{Simple Higher Order System}
\begin{comment}
\end{comment}
Suppose the dynamical system follows the expression $\dst{\overset{m}{x} = Ax}$, a similar technique with eigenvalues and eigenvectors may be employed along with the roots of unity. By conjecture, the partial solution to the dynamical system $\dst{\overset{m}{x} = Ax}$ follows
$$x_p = \b{v_i}e^{\a_i t}$$
$$\dot{x_p} = \a_i\b{v_i}e^{\a_i t}$$
$$\ddot{x_p} = \a_i^2\b{v_i}e^{\a_i t}$$
$$\overset{m}{x_p} = \a_i^m\b{v_i}e^{\a_i t}$$
$$Ax_p = \overset{m}{x_p}$$
$$A \b{v_i}e^{\a_i t}= \a_i^m\b{v_i}e^{\a_i t}$$
$$A \b{v_i}= \a_i^m\b{v_i}$$
\\Since $\dst{A \b{v_i}= \a_i^m\b{v_i}}$ wherein $\dst{\la_i}$ are eigenvalues of $A$, then $\la_i = \a_i^m$. Since $\la_i$ may be a complex number, $\a_i$ must be the roots of unity to the complex number $\la_i$. If $\la_i = a+bi$
$$\a_n = (a^2 + b^2)^{\f{1}{2m}}cis\l[\f{1}{m}arctan\l(\f{b}{a}\r) + \f{2 \pi n}{m}\r]$$
The general solution to the problem must be the linear combination of the partial solutions $\dst{\sum_{i = 1}^m\l[c_i\b{v_i}e^{\a_{in} t}\r]}$ wherein $c_i$ are constants determined by the initial conditions and $\a_{in}$ represents the $n^{th}$ root of unity of the $i^{th}$ eigenvalue albeit complex or real. 
%Seperator
%Seperator
%Seperator
%Seperator
%Seperator
\section{Simple $n^{th}$ Order Homogenous System}
\begin{comment}
\end{comment}
Suppose the differential equation follows the expression:
$$0 = \sum_{i = 0}^{m}{[A_i \overset{i}{x}]} = A_0 x + A_1 \dot{x} + A_2 \ddot{x}+ \dots + A_{i - 1} \overset{i -  1}{x} + A_{i} \overset{i}{x}$$
\\The general solution to the system above is a linear combination of the partial solutions, $\dst{x(t) = \sum_{j = 1}^{n}{[c_j \b{v_j}e^{\la_j t}]}}$ wherein partial solutions are defined as $\dst{x_{partial}(t) = c_j \b{v_j}e^{\la_j t}}$ and $c_1, c_2 \dots c_n$ are constants determined by the initial value of the problem. 
$$x_{p}(t) = c_j \b{v_j}e^{\la_j t}$$
$$\overset{k}{x_{p}(t)} = c_j \b{v_j}\la_{j}^k e^{\la_j t}$$
$$0 = \sum_{i = 0}^{m}{[A_i \b{v_j} c_j \la_{j}^i e^{\la_j t}]} =A_0 \b{v_j} c_j e^{\la_j t} + A_1 \b{v_j} c_j \la_{j} e^{\la_j t} + \dots + A_m \b{v_j} c_j \la_{j}^m e^{\la_j t}$$
\\For the non-trivial solutions to the homoegenous system of differential equations, $\dst{c_j, \b{v_j}, \la_j \neq 0}$. The function $\dst{e^{\la_j t}}\neq 0$ for all time. Therefore, 
$$0 = \l\{ \sum_{i = 0}^{m}{[A_i \la_{j}^i]} \r\} \b{v_j}$$
\\For $\dst{\b{v_j} \neq 0}$, the matrix $\dst{\sum_{i = 0}^{m}{[A_i \la_{j}^i]}}$ must be non-invertible. Therefore, $\dst{det\l\{ \sum_{i = 0}^{m}{[A_i \la_{j}^i]} \r\} = 0}$
\\The expressions for $\dst{\la_j ^ i}$ could be substituted to the expression $\dst{A_i \la_{j}^i} \b{v_j} = 0$ to express vector $\dst{\b{v_j}}$ explicitly.






















\end{center}

\end{document}
