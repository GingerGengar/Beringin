\documentclass[a4paper, 12pt]{report}
\usepackage{hyperref}
\def\t{\theta}
\def\w{\omega}
\def\a{\alpha}
\def\be{\beta}
\def\la{\lambda}
\def\g{\gamma}
\def\f{\frac}
\def\l{\left}
\def\r{\right}
\def\dst{\displaystyle}
\def\b{\bar}
\def\h{\hat}
\def\ph{\phi}
\def\d{\cdot}
\def\n{\nabla}
\def\p{\partial}
\def\lap{\mathcal{L}}
\usepackage{amsmath}
\usepackage{esint}
\usepackage{comment}
\usepackage{amssymb}
\usepackage{commath}
\usepackage{geometry}

\let\stdsection\section
\renewcommand\section{\newpage\stdsection}
\setcounter{MaxMatrixCols}{20}
\geometry{portrait, margin=0.8in}

\begin{comment}
Document Philosophy:
Part of the original intention of the Archives Series Project began in an effort to preserve some of the most general and powerful mathematical techniques I learned during my time in Purdue. The Project began as a way of archiving oneself's skills at the peak of performance in case it would ever be needed again one day. Along the way, I was posed with a few important question "Why is this Archive Necessary?", "Couldn't we just refer back to the original textbooks and sources of the Archives?" "What sets such an Archive different than the multitudes of other textbooks that exist out there?"

In my humble opinion I believe that writing and giving names to mathematical objects is a pre-requisite to mathematics. It is impossible to do mathematics without definition of terms, and the notation of the terms are closely related to the definition of terms. Since the intimate relationship between notation and definition is so important, uniting various sources with differing notations under a unified consistent notation style ensures that the information discussed in this document is easily readable provided one learns the notation convention defined along the discussion. This guarantees an ease of information absorption and allows the powerful general mathematical theorem in this document to reach its maximum ease of use without compromising generality.

This calls for the implementation of a series of supposed rules that govern the document. Although not all parts of the documents currently adhere to said rules, this should be a kind of standard that should be achieved in due time for this document to fully implement the principles stated above:

1.) Theorems presented in the document must contain Proofs

2.) Each difference in line or after an = sign, there should be a maximum of 2 similar mathematical operations algebraic operations performed.

3.) Observations should be explained and the types of variables as mathematical objects must be defined within the scope of the theory (Is x a vector? Matrix? Tensor? Real? Complex?) (Is \times a cross product or an algebraic multiplication?)

4.) The inputs and outputs of the functions produced as a consequence of the mathematical theorems must be clearly defined as said mathematical objects.

5.) The Document must not include any examples to make it concise and helpful. Examples may be defined in a seperate document. But not this one, because it has to be concise.

6.) The proof of theorems found in this document should be replaced if a more elegant proof appears.
\end{comment}

\begin{document}

%%Title
\title{Mathematics Archives}
\author{Hans C. Suganda}
\date{$25^{th}$ February 2021}
\maketitle
\newpage

\tableofcontents

\begin{center}
\section{Linear Differential Equations}
%Seperator
%General Definition 
\subsection{Definition of Differential Operator}
Let the differential operator be defined as the following: 
$$L = \sum_{i = 0}^{n}\l[a_i \f{d^{n - i}}{dx^{n - i}}\r] = a_0 \f{d^{n }}{dx^{n}} + a_1 \f{d^{n - 1}}{dx^{n - 1}}+ \dots + a_{n - 1}\f{d}{dx} + a_n$$
Let the following operator $D$ be defined:
$$D = \f{d}{dx} \qquad D^k = \f{d^k}{dx^k}$$
\\Therefore, the linear differential operator could be defined as 
$$L = \sum_{i = 0}^{n}\l[a_i D^{n - i}\r] = a_0\prod_{i = 1}^{n}\l[D - r_i\r]$$
\\wherein $a_i$ and $r_i$ are constants albeit complex or real. The notation above is always true because an fundamental theorem of algebra states that $n^{th}$ order polynomial must have $n$ roots. Since linear differential operator could be expressed as a polynomial in terms of the operator $D$, therefore the notation above would always be true regardless of the choice of $a_i$ and $n$. The linear differential operator have certain properties associated to them discussed in the propositions,
%Seperator
%The first conjecture
\subsection{Proposition 1: Operation on 0} 
The linear differential operator when operated on a 0 will yield 0:
$$L[0]=\sum_{i = 0}^{n}\l[a_i D^{n - i}\r]0=a_0 \f{d^{n }}{dx^{n}}0 + a_1 \f{d^{n - 1}}{dx^{n - 1}}0+ \dots + a_{n - 1}\f{d}{dx}0 + a_n0$$ 
\\It is given that $\dst{\f{d}{dx}(0) = 0}$, and by reapplying recursively, $\dst{\f{d^k}{dx^k}(0) = 0}$. Therefore, 
$$L[0]=0$$
%Seperator
%The second conjecture
\subsection{Proposition 2: Operation on Constants}
The linear differential operator when operated on a constant will yield some constant provided that $a_n \neq 0$:
$$L[c] = \sum_{i = 0}^{n}\l[a_i D^{n - i}\r]c = a_0 \f{d^{n }}{dx^{n}}c + a_1 \f{d^{n - 1}}{dx^{n - 1}}c+ \dots + a_{n - 1}\f{d}{dx}c + a_nc$$
\\Considering $\dst{\f{d}{dx}c = \f{d^k}{dx^k}c = 0}$,
$$L[c] = \sum_{i = 0}^{n}\l[a_i D^{n - i}\r]c = a_nc$$
%Seperator
%The third conjecture
\subsection{Proposition 3: Operation Commutativity}
If there exist two linearly independent differential operators $L_1$ and $L_2$, then the solution of the system $0 = L_1L_2[y]$ must be a linear combination of the solution to the system $0 = L_1[y]$ and $0 = L_2[y]$:
$$L_1=\prod_{i = 0}^{m}\l[D - \alpha_{i}\r] \quad,\quad L_2=\prod_{j = 0}^{n}\l[D - \be_{j}\r]$$
\\Let $y_1(x)$ and $y_2(x)$ be such that:
$$0 = L_1[y_1(x)]=\prod_{i = 0}^{m}\l[D - \alpha_{i}\r]y_1(x) \quad,\quad 0 = L_2[y_2(x)]=\prod_{j = 0}^{n}\l[D - \be_{j}\r]y_2(x)$$
\\Let $T_i$ be the transformation defined as $T_i: f(x) \to g(x)\quad , \quad T_i[f(x)] = (D - r_i)f(x) $, wherein $f(x)$ is some arbitrary continuous function over some interval. Indeed the transformation $T_1$ is linear:
$$T_i[cu(x)] = (D - r_i)cu(x)$$ 
$$T_i[cu(x)] = c(D - r_i)u(x)$$
$$cT_i[u(x)] = c(D - r_i)u(x)$$
\\Therefore, $T_i[cu(x)] = cT_i[u(x)]$ wherein $c$ is some arbitrary constant.
$$T_i[u(x) + v(x)] = (D - r_i)[u(x) + v(x)]$$
$$T_i[u(x) + v(x)] = (D - r_i)[u(x)] + (D - r_i)[v(x)]$$
$$T_i[u(x)] + T_i[v(x)] = (D - r_i)[u(x)] + (D - r_i)[v(x)]$$
\\Therefore, $T_i[u(x) +v(x)] = T_i[u(x)] + T_i[v(x)]$, and $T_i$ must be a linear transformation. Linear transformations applied compositely form a linear transformation:
$$T_0(u + v) = T_0(u) + T_0(v)$$
$$T_1[T_0(u + v)] = T_1[T_0(u)] + T_1[T_0(v)]$$
$$\prod_{i = 0}^{\a}\l[T_i\r](u + v) = \prod_{i = 0}^{\a}\l[T_i\r](u) + \prod_{i = 0}^{\a}\l[T_i\r](v)$$
\\Since $L_1$ and $L_2$ is only a specific case of the transformation described as $T_1$ it can be considered that the differential operators of $L_1$ and $L_2$ are linear. Therefore, it can be said that $L_1[L_2]$ must be linear. 
$$0 =null = L_1[y_1(x)]=\prod_{i = 0}^{m}\l[D - \alpha_{i}\r]y_1(x)\quad,\quad 0 = null = L_2[y_2(x)]=\prod_{j = 0}^{n}\l[D - \be_{j}\r]y_2(x)$$
\\For $y_1(x)$ and $y_2(x)$:
$$0 =null = L_2\{L_1[y_1(x)]\}=\prod_{j = 0}^{n}\l[D - \be_{j}\r]\prod_{i = 0}^{m}\l[D - \alpha_{i}\r]y_1(x)$$
$$0 = null = L_1\{L_2[y_2(x)]\} = \prod_{i = 0}^{m}\l[D - \alpha_{i}\r]\prod_{j = 0}^{n}\l[D - \be_{j}\r]y_2(x)$$
$$\prod_{i = 0}^{m}\l[D - \alpha_{i}\r]\prod_{j = 0}^{n}\l[D - \be_{j}\r] = \prod_{j = 0}^{n}\l[D - \be_{j}\r]\prod_{i = 0}^{m}\l[D - \alpha_{i}\r] = L_1[L_2] = L_2[L_1]$$
\\It follows by definition of linear transformation that, $L_1[k_1y_1(x)] = k_1L_1[y_1(x)] = null$ and that $L_2[k_2y_2(x)] = k_2L_2[y2(x)] = null$:
$$0 =null = L_2\{L_1[k_1y_1(x)]\}=\prod_{j = 0}^{n}\l[D - \be_{j}\r]\prod_{i = 0}^{m}\l[D - \alpha_{i}\r]k_1y_1(x)$$
$$0 = null = L_1\{L_2[k_2y_2(x)]\} = \prod_{i = 0}^{m}\l[D - \alpha_{i}\r]\prod_{j = 0}^{n}\l[D - \be_{j}\r]k_2y_2(x)$$
$$0 = L_2\{L_1[k_1y_1(x)]\} + L_2\{L_1[k_2y_2(x)]\} = L_2\{L_1[k_1y_1(x) + k_2y_2(x)]\}$$
$$0  = \prod_{i = 0}^{m}\l[D - \alpha_{i}\r]\prod_{j = 0}^{n}\l[D - \be_{j}\r][k_1y_1(x) + k_2y_2(x)]$$
%Seperator
%End of conjectures
\subsection{Homogenous Differential Equation Cases}
Consider the following homogenous differential equation:
$$0 = \sum_{i = 0}^{n}\l[a_i\overset{n-i}{y}\r] = a_0 \overset{n}{y} + a_1 \overset{n - 1}{y} + \dots + a_{n-1} \dot{y} + a_n y$$
$$0 = L[y] = \sum_{i = 0}^{n}\l[a_i D^{n - i}\r]y = \prod_{i = 1}^{n}\l[D - r_i\r]y$$
%Seperator
%Non Repeated Roots
\subsubsection{Non-Repeated Roots}
By principle of superposition verified by proposition 1 and 3, the general solution to the homogenous $n^{th}$ order differential equation,
$$y_c = \sum_{i = 1}^{n}\l[c_i y_i\r]$$
\\Wherein $c_i$ represents either complex or real constants, $y_i$ represents solutions to the $0 = [D - r_i]y_i$ system. Considering the partial system,
$$0 = [D - r_i]y_i$$
$$0 = Dy_i - r_i y_i$$
$$\f{d}{dx}(y_i) = r_i y_i $$
$$\int \f{1}{y_i}dy_i = \int r_i dx $$
$$\ln{y_i} = r_i x + C$$
$$y_i = e^{r_i x + C} = c_i e^{r_i x}$$
Therefore for as long as there are no roots with multiplicity greater than 1, the following is true, for some choice of constants,
$$y_c = \sum_{i = 1}^{n}\l[c_i e^{r_i x}\r]$$
%Seperator
%Repeated Roots
\subsubsection{Repeated Roots}
Suppose the $\a^{th}$ root has a multiplicity of $k$, 
$$0 = \prod_{i = 1}^{\a - 1}\l[D - r_i\r]\prod_{j = \a + k}^{n}\l[D - r_i\r](D - r_\a)^ky$$
\\By proposition 3, the general solution to the system must be the linear combination:
$$y_g(x) = c_1 y_1(x) + c_2 y_2(x)$$
wherein $y_1(x)$ is the solution to the system $\dst{0 = \prod_{i = 1}^{\a - 1}\l[D - r_i\r]\prod_{j = \a + k}^{n}\l[D - r_i\r]y}$ and $y_2(x)$ is the solution to the system $\dst{ 0 = (D - r_\a)^ky}$. By conjecture, it is suspected that the $\dst{y_2(x) = u(x)e^{r_\a x}}$ wherein $u(x)$ is some function to be determined. 
$$0 = (D - r_\a) u(x)e^{r_\a x}$$
$$0 = \f{d}{dx}\l[u(x)e^{r_\a x}\r] - r_\a u(x)e^{r_\a x}$$
$$0 = \overset{1}{u(x)}e^{r_\a x} + r_\a u(x)e^{r_\a x}  - r_\a u(x)e^{r_\a x}$$
$$0 = \overset{1}{u(x)}e^{r_\a x}$$
By reapplying the linear differential operator recursively:
$$(D - r_\a)^k u(x) e^{r_\a x} = \overset{k}{u(x)}e^{r_a x}$$
\\Therefore, the system would follow:
$$0 = (D - r_\a)^k u(x)e^{r_\a x} = \overset{k}{u(x)}e^{r_a x}$$
$0 \neq e^{r_a x}$ for all $x$
$$0 = \overset{k}{u(x)}$$
\\A function that satisfies the following condition must be a polynomial with at most degree $k - 1$. Therefore, 
$$u(x) = \sum_{i = 0}^{k - 1}\l[c_i x ^{k - 1 - i} \r]$$
The general solution $y_{rr}(x)$ to the system $\dst{ 0 = (D - r_\a)^ky}$:
$$y_{rr}(x) = \sum_{i = 0}^{k - 1}\l[c_i x ^{k - 1 - i} \r] e^{r_\a x}$$
%Seperator
%Complex Roots
\subsubsection{Complex Roots}
Suppose the $\a^{th}$ root is a complex root, by the fundamental theorem of algebra, some other root must be its complex conjugate. Let the complex conjugate root of the $\a^{th}$ root be ordered next to the $\a^{th}$ root in the product notation. Therefore, 
$$0 = \prod_{i = 1}^{\a - 1}\l[D - r_i \r]\prod_{i = \a + 2}^{n}\l[D - r_i\ \r][D - r_{\a}][D - r_{\a +1 }]y$$
Let $y_{cr}$ represent the complex root corresponding to the system $0 = [D - r_{\a}][D - r_{\a +1 }]y_{cr}$ . By principle of superposition verified by proposition 1 and 3, 
$$y_c = \sum_{i = 1}^{n - 2}\l[c_i e^{r_i x}\r] + y_{cr}$$
$$0 = [D - r_{\a}][D - r_{\a +1 }]y_{cr}$$
\\By the principles presented earlier,
$$y_{cr}(x) = c_{\a} e^{(a + bi)x} +c_{\a + 1} e^{(a - bi)x}$$
$$y_{cr}(x) = e^{ax}\l[c_{\a} e^{bxi} +c_{\a + 1} e^{- bxi}\r]$$
By De Moivre's theorem,
$$e^{bxi} = \cos{(bx)} + i\sin{(bx)} \quad, \quad e^{-bxi} = \cos{(bx)} - i\sin{(bx)}$$
\\Suppose the constants $c_{\a}$ and $c_{\a + 1}$ are complex numbers,
$$c_{\a} = f_1 + g_1 i \quad, \quad c_{\a + 1} = f_2 + g_2 i$$
By substituting to the expression for complex solution,
$$y_{cr}(x) = e^{ax}\l[(f_1 + g_1 i) e^{bxi} + (f_2 + g_2 i) e^{- bxi}\r]$$
\\Let $y_{cr} = e^{ax} y_{co},$
$$y_{co} = c_{\a} e^{bxi} + c_{\a + 1} e^{- bxi}$$
$$y_{co}(x) =(f_1 + g_1 i) e^{bxi} + (f_2 + g_2 i) e^{- bxi}$$
$$y_{co}(x) =(f_1 + g_1 i)[\cos{(bx)} + i\sin{(bx)}]  + (f_2 + g_2 i) [\cos{(bx)} - i\sin{(bx)}]$$
\\Let
$$A(x) = (f_1 + g_1 i)[\cos{(bx)} + i\sin{(bx)}]\quad , \quad B(x) = (f_2 + g_2 i) [\cos{(bx)} - i\sin{(bx)}]$$
$$A(x) = f_1\cos{(bx)} - g_1 \sin{(bx)} + i[f_1\sin{(bx)} + g_1\cos{(bx)}]$$
$$ B(x) = f_2\cos{(bx)} + g_2 \sin{(bx)} + i[ - f_2\sin{(bx)} + g_2\cos{(bx)}]$$
$$y_{co}(x) = A(x) + B(x)$$
$$y_{co}(x) = (f_1 + f_2)\cos{(bx)} + (g_2 - g_1 )\sin{(bx)} + i[(f_1 - f_2)\sin{(bx)} + (g_1 + g_2)\cos{(bx)}]$$
\\For the complex root $y_{cr}(x)$ to be real, the imaginary component of $y_{cr}(x)$ must be equals to $0$. Therefore, the following must hold true,
$$f_1 = f_2 \quad, \quad g_1 = -g_2$$
For as long as the condition above hold true, the two constants $c_{\a}$ and$c_{\a + 1}$ must be complex conjugates. Considering the case wherein $c_{\a}$ and$c_{\a + 1}$ as complex conjugates,
$$y_{co}(x) = 2 f_1\cos{(bx)} + 2 g_2\sin{(bx)}$$
$$y_{cr} = 2e^{ax}[f_1\cos{(bx)} + g_2\sin{(bx)}]$$
\\Therefore, the following is true for each complex root and conjugate pair,
$$y_c = \sum_{i = 1}^{n - 2}\l[c_i e^{r_i x}\r] + 2e^{ax}[f_1\cos{(bx)} + g_2\sin{(bx)}]$$
%Seperator
%Repeated Complex Roots
\subsubsection{Repeated Complex Roots}
Suppose the $\a^{th}$ root is a complex root with a multiplicity of $k$. Let its complex conjugate be placed adjacent after said complex root,
$$0 = \prod_{i = 1}^{\a - 1}\l[D - r_i\r]\prod_{i = \a + 2k}^{n}\l[D - r_i\r]\l[D - r_{\a}\r]^{k}\l[D - \bar{r_{\a}}\r]^{k}y$$
\\Let $y_{crr}$ be considered as the solution to the system $0 = \l[D - r_{\a}\r]^{k}\l[D - \bar{r_{\a}}\r]^{k}y_{crr}$ . Based on superposition verified by proposition 1 and 3, 
$$y_c = \sum_{i = 1}^{n - 2k}\l[c_i e^{r_i x}\r] + y_{crr}$$
\\Based on the previous work on repeated roots with multiplicity greater than 1,
$$y_{crr}(x) = \sum_{i = 0}^{k - 1}\l[c_i x ^{k - 1 - i} \r] C_1 e^{r_\a x} + \sum_{i = 0}^{k - 1}\l[c_i x ^{k - 1 - i} \r] C_2 e^{\bar{r_\a} x}$$ 
\\Let $r_{\a} = a + bi$, and $\bar{r_\a} = a - bi$, 
$$y_{crr}(x) = \sum_{i = 0}^{k - 1}\l[c_i x ^{k - 1 - i} \r] [C_1 e^{bxi} + C_2 e^{-bxi}] e^{ax}$$
\\Let $c_{1} = f_1 + g_1 i$ and $c_{2} = f_2 + g_2 i$ . Based on previous work on complex roots,
$$C_1 e^{bxi} + C_2 e^{- bxi} = 2 f_1\cos{(bx)} + 2 g_2\sin{(bx)}$$
\\Therefore,
$$y_{crr}(x) = \sum_{i = 0}^{k - 1}\l[c_i x ^{k - 1 - i} \r] [2 f_1\cos{(bx)} + 2 g_2\sin{(bx)}] e^{ax}$$
%Seperator
%Combined Form
\subsection{General Solutions to Homogenous Differential Equations}
Therefore, if an $n^{th}$ order homogeneous differential equation with $a$ real non-repeated roots, $b$ complex root pairs, $c$ real repeated roots with multiplicity $\g$, and $d$ complex repeated root pairs with multiplicity $\be$
\begin{align*}
y_c  &= \sum_{l =1}^{a}\l[c_{1,l}e^{r_{1,l}x}\r]\\ 
&\quad + \sum_{j =1}^{b}[c_{2,j,1} \cos{(b_{1,j} x)} + c_{2,j,2} \sin{(b_{1,j} x)}]e^{a_{1,j} x}\\ 
&\quad + \sum_{k =1}^{c}\l[\sum_{m = 0}^{\g_k - 1}\l[c_{3,m,k} x ^{\g_k - 1 - m} \r] e^{r_{k} x}\r]\\
&\quad + \sum_{i =1}^{d}\l[\sum_{p = 0}^{\be_p - 1}\l[c_{4,p,i} x ^{\be_p - 1 - p} \r][k_{4,i,1}\cos{(b_{2,i})x} + k_{4,i,2}\sin{(b_{2,i})x}] e^{r_{i} x}\r]
\end{align*}
\\The variables $a$, $b$, $c$, $d$, $\g$, $\be$, and $n$ are related by the following expression,
$$n = a + 2b + \sum_{i = 1}^{c}[\g_{i}] + \sum_{j = 1}^{d}[2\be_{j}]$$
%Seperator
%Non-Homogenous Differential Equation Cases
\subsection{Non-Homogenous Differential Equations}
Consider the following system:
$$\sum_{i = 0}^{n}\l[a_i \overset{n - i}{y}\r] = \sum_{j = 0}^{m}\l[c_i f_i(x)\r]$$
\\wherein $f_i(x)$ represents the $i^{th}$ arbitrary function, and $a_i$ represents the $i^{th}$ arbitrary constant. The following function could be rewritten in terms of the linear differential operator $L$:
$$L[y] = \sum_{j = 0}^{m}\l[c_i f_i(x)\r]$$
\\Let $y_j$ represent the general solution to the $j^{th}$ system:
$$L[y_j] = c_i f_j(x)$$
By taking the summations of the various solutions to the various sytems:
$$L[y_0] + L[y_1] + \dots +L[y_{j - 1}] + L[y_j] = c_0 f_0(x) + c_1 f_1(x) + \dots + c_{j - 1} f_{j - 1}(x) + c_{j} f_j(x)$$
\\Since the differential operator $L$ is linear, as shown in proposition 3: 
$$L\l[\sum_{j = 0}^{m}\l(y_j\r)\r] = L[y_0] + L[y_1] + \dots +L[y_{j - 1}] + L[y_j]$$
$$L\l[\sum_{j = 0}^{m}\l(y_j\r)\r] =  \sum_{j = 0}^{m}\l[c_i f_i(x)\r] $$
\\Therefore, a solution to the non-homogenous differential equation:
$$y_p(x) = \sum_{j = 0}^{m}\l(y_j\r)$$ 
An $m^{th}$ dimensional subspace spanned by $m$ functions must always contain a null element, in this case, a zero function. Let the $y_c$ represent the general solution to the homogenous differential equation $Ly = null = 0$. Then the general solution must follow:
$$y_g(x) = \sum_{j = 0}^{m}\l(y_j\r) + y_c$$
%Seperator
%Seperator
%Seperator
\section{Dynamical Systems: Eigenvalues and Eigenvectors}
Let A represent a $n \times n$ matrix (a matrix with n rows and n columns), $x$ represent a column vector of $n$ variables and $x'$ represent the derivative of the column vector $x$. The system below is known as a dynamical system:
$$x' = Ax$$   
\\Consider the dynamical system $x' = kx$ wherein k is some arbitrary constant. Therefore,
$$\f{dx}{dt} = kx$$
$$dt = \f{1}{kx}dx$$
$$\int dt = \int \f{1}{kx}dx$$
$$t = \f{1}{k}\ln{x}+ C$$
$$\ln{x} = kt + C$$
$$x = Ce^{kt}$$
\\Wherein C is a constant determined by the initial conditions.
%Seperator
%Seperator 
\subsection{Non-Repeated Real Eigenvalues of n $\times$ n Case}
The previous working gives the conjecture that the general solution set $x(t)$ to the dynamical system $x' = Ax$ is the linear combination of exponential functions analogous to the example shown above. Consider the possibility that one solution to the dynamical system takes the form below:
$$x(t) = \b{v_i}e^{\la_i t}$$
\\wherein $\b{v_i}$ represents a vector and $\la_i$ represents a constant. By taking derivative of the solution, 
$$x'(t) = \la_i\b{v_i}e^{\la_i t}$$
$$Ax(t) = A\b{v_i}e^{\la_i t}$$
\\By considering that $x(t)$ represents a solution to the dynamical system, $\dst{x' = Ax}$
$$\la_i\b{v_i}e^{\la_i t} = A\b{v_i}e^{\la_i t}$$
Since $e^{\la_i t} \neq 0$ for all values of $t$,
$$A\b{v_i} = \la_i\b{v_i}$$
\\This is a familiar equation for eigenvalues and eigenvectors. This shows that each eigenvalue-eigenvector pairs of the matrix $A$ represents a solution set. Therefore, the general solution set is:
$$x(t) = span[\b{v_1}e^{\a_1 t}, \b{v_2}e^{\a_2 t}, \dots \b{v_n}e^{\a_n t}]$$
$$x(t) = \sum_{i = 1}^{n} \l[c_i\b{v_i}e^{\la_i t}\r]$$
wherein $c_i$ are constants determined by the initial value of the problem. 
%Seperator
%Seperator
\subsection{Non-Repeated Complex Eigenvalues of 2 $\times$ 2 Case}
Consider the special case wherein the matrix A is a $2\times2$ matrix and that the eigenvalues are complex, by conjecture,
$$x(t) = c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = k_1Re[\b{v_1}e^{\la_1 t}] + k_2Im[\b{v_1}e^{\la_1 t}]$$
\\wherein $c_1$ and $c_2$ are complex values meanwhile $k_1$ and $k_2$ are real values. There must always be some choice of complex values $c_1$ and $c_2$ such that the expression above is true. The proof is shown below,
\\~\\Let 
$$\b{v_1} = \b{v_r} + i\b{v_i}\qquad \la_1 = a + bi$$
$$x(t) = (\b{v_r} + i\b{v_i})e^{(a+bi)t}$$
$$x(t) = e^{at}(\b{v_r} + i\b{v_i})[\cos{(bt)} + i\sin{(bt)}]$$
$$x(t) = e^{at}[\b{v_r}\cos{(bt)} + i\b{v_r}\sin{(bt)} + i\b{v_i}\cos{(bt)} - \b{v_i}\sin{(bt)}]$$
$$x(t) = e^{at}[\b{v_r}\cos{(bt)} - \b{v_i}\sin{(bt)}]+ ie^{at}[\b{v_r}\sin{(bt)} + \b{v_i}\cos{(bt)}]$$
$$Re[\b{v_1}e^{\la_1 t}] = e^{at}[\b{v_r}\cos{(bt)} - \b{v_i}\sin{(bt)}]$$
$$Im[\b{v_1}e^{\la_1 t}] = e^{at}[\b{v_r}\sin{(bt)} + \b{v_i}\cos{(bt)}]$$
$$LHS = k_1Re[\b{v_1}e^{\la_1 t}] + k_2Im[\b{v_1}e^{\la_1 t}]$$
$$LHS = k_1e^{at}[\b{v_r}\cos{(bt)} - \b{v_i}\sin{(bt)}] + k_2e^{at}[\b{v_r}\sin{(bt)} + \b{v_i}\cos{(bt)}]$$
$$LHS = e^{at}[k_1\b{v_r}\cos{(bt)} - k_1\b{v_i}\sin{(bt)} + k_2\b{v_r}\sin{(bt)} + k_2\b{v_i}\cos{(bt)}]$$
$$LHS = e^{at}\{[k_1\b{v_r}+ k_2\b{v_i}]\cos{(bt)}  + [k_2\b{v_r}- k_1\b{v_i}]\sin{(bt)}\}$$
$$LHS = e^{at}[k_1\b{v_r}+ k_2\b{v_i}]\cos{(bt)}  + e^{at}[k_2\b{v_r}- k_1\b{v_i}]\sin{(bt)}$$
\\It is important to note that eigenvalues and their corresponding eigenvectors occur in conjugate pairs. Therefore, if $\la_1 = a+bi$, then $\la_2 = \la_1^\ast = a - bi$ and if the eigenvector $\b{v_1} = \b{v_r} + i\b{v_i}$, then $\b{v_2} =\b{v_1}^\ast= \b{v_r} - i\b{v_i}$.
\\~\\Let
$$c_1 = f_1 + g_1i\qquad c_2 = f_2 + g_2i$$
$$c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = (f_1 + g_1i)(\b{v_r} + i\b{v_i})e^{(a+bi)t} + (f_2 + g_2i)(\b{v_r} - i\b{v_i})e^{(a-bi)t}$$
\\For ease of notation,
$$A(t) = (f_1 + g_1i)(\b{v_r} + i\b{v_i})e^{(a+bi)t}\qquad B(t) = (f_2 + g_2i)(\b{v_r} - i\b{v_i})e^{(a-bi)t}$$
%Restatement of the original LHS of the equation
$$c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = A(t) + B(t)$$
%Beginning of the script for the "A" components
$$A(t) = e^{at}(f_1 + g_1i)(\b{v_r} + i\b{v_i})\l[\cos{(bt)} + i \sin{(bt)}\r]$$
$$A(t) = e^{at}(f_1\b{v_r} + if_1\b{v_i} + ig_1\b{v_r} - g_1\b{v_i})\l[\cos{(bt)} + i \sin{(bt)}\r]$$
$$A(t) = e^{at}[f_1\b{v_r} - g_1\b{v_i}+ i(f_1\b{v_i} + g_1\b{v_r})]\l[\cos{(bt)} + i \sin{(bt)}\r]$$
$$A(t) = e^{at}[(f_1\b{v_r} - g_1\b{v_i})\cos{(bt)} + i(f_1\b{v_i} + g_1\b{v_r})\cos{(bt)} + i(f_1\b{v_r} - g_1\b{v_i})\sin{(bt)} - (f_1\b{v_i} + g_1\b{v_r})\sin{(bt)}]$$
%Beginning of the script for the "B" components
$$B(t) = (f_2 + g_2i)(\b{v_r} - i\b{v_i})e^{(a-bi)t}$$
$$B(t) = e^{at}(f_2\b{v_r} - if_2\b{v_i} + ig_2\b{v_r} + g_2\b{v_i})\l[\cos{(-bt)} + i\sin{(-bt)}\r]$$
$$B(t) = e^{at}[(f_2\b{v_r} + g_2\b{v_i}) + i(g_2\b{v_r} - f_2\b{v_i})]\l[\cos{(bt)} - i\sin{(bt)}\r]$$
$$B(t) = e^{at}[(f_2\b{v_r} + g_2\b{v_i})\cos{(bt)} + i(g_2\b{v_r} - f_2\b{v_i})\cos{(bt)} + i(-f_2\b{v_r} - g_2\b{v_i})\sin{(bt)} + (g_2\b{v_r} - f_2\b{v_i})\sin{(bt)}]$$
%End of the script for the "B" components
$$c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = Re[A(t)] + Re[B(t)] + i\{Im[A(t)] + Im[B(t)]\}$$
$$0 = Im[A(t)] + Im[B(t)]$$
$$0 = (f_1\b{v_i} + g_1\b{v_r})\cos{(bt)} + (f_1\b{v_r} - g_1\b{v_i})\sin{(bt)} + (g_2\b{v_r} - f_2\b{v_i})\cos{(bt)} - (f_2\b{v_r} + g_2\b{v_i})\sin{(bt)}$$
$$0 = (f_1\b{v_i} + g_1\b{v_r} + g_2\b{v_r} - f_2\b{v_i})\cos{(bt)} + (f_1\b{v_r} - g_1\b{v_i} -f_2\b{v_r} - g_2\b{v_i})\sin{bt}$$
$$0 = [(g_1 + g_2)\b{v_r} + (f_1 - f_2)\b{v_i}]\cos{(bt)} + [(f_1 - f_2)\b{v_r} - (g_1 + g_2)\b{v_i}]\sin{(bt)}$$
\\For as long as the condition below is met, the imaginary component of $A(t) + B(t)$ is negligible.
$$g_1 = -g_2 \qquad f_1 = f_2$$
$$c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = Re[A(t)] + Re[B(t)] $$
\begin{equation*}
\begin{split}c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t}  = &e^{at}(f_1\b{v_r} - g_1\b{v_i})\cos{(bt)} - (f_1\b{v_i} + g_1\b{v_r})\sin{(bt)}  \\ &+ (f_2\b{v_r} + g_2\b{v_i})\cos{(bt)} + (g_2\b{v_r} - f_2\b{v_i})\sin{(bt)}
\end{split}
\end{equation*}
$$c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = e^{at}(f_1\b{v_r} - g_1\b{v_i} + f_2\b{v_r} + g_2\b{v_i})\cos{(bt)} + (g_2\b{v_r} - f_2\b{v_i}-f_1\b{v_i} - g_1\b{v_r})\sin{(bt)} $$
$$c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = e^{at}[(f_1 + f_2)\b{v_r} +(g_2- g_1)\b{v_i}]\cos{(bt)} + [(g_2 - g_1\b)\b{v_r} - (f_1 + f_2)\b{v_i}]\sin{(bt)} $$
$$RHS = c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t}$$
$$RHS = e^{at}[(f_1 + f_2)\b{v_r} +(g_2- g_1)\b{v_i}]\cos{(bt)} + e^{at}[(g_2 - g_1)\b{v_r} - (f_1 + f_2)\b{v_i}]\sin{(bt)}$$
$$LHS = e^{at}[k_1\b{v_r}+ k_2\b{v_i}]\cos{(bt)}  + e^{at}[k_2\b{v_r}- k_1\b{v_i}]\sin{(bt)}$$
\\If the conditions below are met, therefore $LHS = RHS$ and the statement $\dst{x(t) = c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = k_1Re[\b{v_1}e^{\la_1 t}] + k_2Im[\b{v_1}e^{\la_1 t}]}$ is true. 
$$g_1 + g_2 =0 \qquad f_1 + f_2 - k_1 = 0 \qquad f_1 - f_2 = 0 \qquad g_2 - g_1 - k_2 = 0$$
\\The corresponding augmented matrix of the following conditions is
\begin{equation*}
\begin{split}
\begin{matrix}f_1 & f_2 & g_1 & g_2 & k_1 & k_2 & C \end{matrix} \\ \begin{pmatrix}1 & 1 & 0 &0 &-1 &0 &0 \\1 &-1 &0 &0 &0 &0 &0 \\ 0&0 &1 &-1 &0 &1 &0  \\ 0&0 &1 &1 &0 &0 &0 \end{pmatrix}
\end{split}
\end{equation*}
\\The row-reduced echelon form of the corresponding augmented matrix is
$$\begin{matrix} f_1 & f_2 & g_1 & g_2 & k_1 & k_2 & C \end{matrix}$$
$$\begin{pmatrix}1 &0 &0 &0 &-\f{1}{2} &0 &0 \\ 0& 1&0 &0 &-\f{1}{2} &0 &0 \\0 &0 &1 &0 &0 &\f{1}{2} & 0\\0 &0 &0 &1 &0 &-\f{1}{2} &0 \end{pmatrix}$$
\\The row-reduced echelon form is unique and is consistent, therefore the system has a consistent solution. This proves that for some special choice of $c_1$ and $c_2$, the expression below is correct.
$$x(t) = c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} = k_1Re[\b{v_1}e^{\la_1 t}] + k_2Im[\b{v_1}e^{\la_1 t}]$$
A restatement of the general real solution set is:
$$x(t)=k_1e^{at}[\b{v_r}\cos{(bt)} - \b{v_i}\sin{(bt)}] + k_2e^{at}[\b{v_r}\sin{(bt)} + \b{v_i}\cos{(bt)}]$$
The solution set for all real numbers could be better expressed as a matrix multiplication
$$x(t) = e^{at}\begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix} \begin{pmatrix} \cos{(bt)}& -\sin{(bt)} \\ \sin{(bt)}& \cos{(bt)} \end{pmatrix} \begin{pmatrix} k_2 \\ k_1\end{pmatrix}$$
\\The real and imaginary components of the eigenvector $v_1$ form a linearly independent set. Therfore, the matrix $\dst{\begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}}$ must be invertible. Through the invertible matrix theorem, the matrix $\dst{\begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}}$ must have a suitable inverse. 
 $$x(t) = e^{at}\begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix} \begin{pmatrix} \cos{(bt)}& -\sin{(bt)} \\ \sin{(bt)}& \cos{(bt)} \end{pmatrix} \begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}^{-1}  \begin{pmatrix} x_2 \\ x_1\end{pmatrix}$$
 $$x(t) = e^{at}\begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix} \begin{pmatrix} \cos{(bt)}& -\sin{(bt)} \\ \sin{(bt)}& \cos{(bt)} \end{pmatrix} \begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}^{-1}  x_0$$
$$\begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}^{-1}x(t) = e^{at} \begin{pmatrix} \cos{(bt)}& -\sin{(bt)} \\ \sin{(bt)}& \cos{(bt)} \end{pmatrix} \begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}^{-1}  x_0$$
By considering the substitution $\dst{y = \begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}^{-1}x(t)}$ and $\dst{y_0 = \begin{pmatrix}\b{v_i} & \b{v_r} \end{pmatrix}^{-1}  x_0}$,
$$y = e^{at} \begin{pmatrix} \cos{(bt)}& -\sin{(bt)} \\ \sin{(bt)}& \cos{(bt)} \end{pmatrix} y_0$$
\\wherein $e^{at}$ represents a scaling transformation and $\dst{\begin{pmatrix} \cos{(bt)}& -\sin{(bt)} \\ \sin{(bt)}& \cos{(bt)} \end{pmatrix}}$ represents a rotation. Therefore, for a suitable substitution, the general real solution set of the dynamical system $\dst{x' = Ax}$ will form a rotation with a scaling component. The rotation is sometimes known as the "hidden rotation". Some possibilities of the solution set may be ellipses, circles, and spirals. 
%Seperator
%Seperator
\subsection{Non-Repeated Complex Eigenvalues of 3 $\times$ 3 Case}
Consider the case wherein $n = 3$
$$x(t) = \sum_{i=1}^{3}\l[c_i\b{v_i}e^{\la_i t}\r]$$
$$x(t) = c_1\b{v_1}e^{\la_1 t} + c_2\b{v_2}e^{\la_2 t} + c_3\b{v_3}e^{\la_3 t}$$
\\Complex eigenvalues occure in conjugate pairs. When A is a $3 \times 3$ matrix, $2$ of the eigenvalues will be complex conjugate pairs and the third one will be a real value. Therefore, two of the eigenvectors must be complex vectors with the third eigenvector being a real vector. Therefore, through the similar argument and proof written above, 
$$x(t) = k_1Re\l[\b{v_1}e^{\la_1 t}\r] + k_2Re\l[\b{v_1}e^{\la_1 t}\r] + k_3\b{v_3}e^{\la_3 t}$$
$$x(t)=k_1e^{at}[\b{v_r}\cos{(bt)} - \b{v_i}\sin{(bt)}] + k_2e^{at}[\b{v_r}\sin{(bt)} + \b{v_i}\cos{(bt)}] + k_3\b{v_3}e^{\la_3 t}$$
\\The following solution set could be factorised as matrix multiplications
$$x(t) = e^{at} \begin{pmatrix} \b{v_i}&\b{v_r} &\b{v_3} \end{pmatrix} \begin{pmatrix}\cos{(bt)} &-\sin{(bt)} &0\\\sin{(bt)}&\cos{(bt)} & 0\\0& 0& e^{(\la_3 - a)t}\end{pmatrix} \begin{pmatrix} k_2 \\k_1 \\ k_3 \end{pmatrix}$$
The vectors $\b{v_i},\b{v_r},\b{v_3}$ form a linearly independent set, therefore, the matrix $\dst{\begin{pmatrix} \b{v_i}&\b{v_r} &\b{v_3} \end{pmatrix}}$ is invertible and its inverse must exist.
\\Let $\dst{y_0 = \begin{pmatrix} k_2\\k_1 \\k_3 \end{pmatrix}}$ 
$$\begin{pmatrix} \b{v_i}&\b{v_r} &\b{v_3} \end{pmatrix} ^{-1 }x(t) = e^{at} \begin{pmatrix}\cos{(bt)} &-\sin{(bt)} &0\\\sin{(bt)}&\cos{(bt)} & 0\\0& 0& e^{(\la_3 - a)t}\end{pmatrix} y_0$$
\\Let $\dst{y(t) = \begin{pmatrix} \b{v_i}&\b{v_r} &\b{v_3} \end{pmatrix} ^{-1 }x(t)}$
$$y(t) = e^{at} \begin{pmatrix}\cos{(bt)} &-\sin{(bt)} &0\\\sin{(bt)}&\cos{(bt)} & 0\\0& 0& e^{(\la_3 - a)t}\end{pmatrix} y_0$$
\\$y_0$ is dependent on the system's initial conditions. This shows that for some suitable substitution, the general solution set forms a helix. The geometrical implication of the solution set is a spiral around the z-axis while it is moving away from the xy plane. The substitution back into the conventional axis $x_1,x_2,x_3$ could be considered as a transformation that "distorts" the helix. 
%Seperator
%Seperator
\subsection{Repeated Eigenvalues}
Given the matrix $A$ in the system $x' = Ax$ is a matrix with repeated eigenvalues with multiplicity k, a reasonable conjecture is the solution to the system is similar in form to the repeated roots case in the linear differential equation. By conjecture,
$$x(t) = \sum_{i = 0}^{k - 1}\l[\b{v_i} t^{k - 1 - i}e^{\la t}\r]$$
$$x'(t) = \sum_{i = 0}^{k - 1}\l[\b{v_i} \f{d}{dt}\l[t^{k - 1 - i}e^{\la t}\r] \r]$$
$$\f{d}{dt}\l[t^{k - 1 - i}e^{\la t}\r] = (k - 1 - i)t^{k - 2 - i}e^{\la t} + \la t^{k - 1 - i}e^{\la t} $$
$$x'(t) = \sum_{i = 0}^{k - 1}\l[(k - 1 - i)t^{k - 2 - i}\b{v_i}e^{\la t} + \la t^{k - 1 - i}\b{v_i}e^{\la t} \r]$$
Remembering $x'(t) = Ax(t)$,
$$\sum_{i = 0}^{k - 1}\l[A\b{v_i} t^{k - 1 - i}e^{\la t}\r] = \sum_{i = 0}^{k - 1}\l[ (k - 1 - i)t^{k - 2 - i}\b{v_i}e^{\la t} + \la t^{k - 1 - i}\b{v_i}e^{\la t} \r]$$
Considering that $e^{\la t} \neq 0$, therefore, 
$$\sum_{i = 0}^{k - 1}\l[A\b{v_i} t^{k - 1 - i}\r] = \sum_{i = 0}^{k - 1}\l[ \la t^{k - 1 - i}\b{v_i} + (k - 1 - i)t^{k - 2 - i}\b{v_i}\r]$$
\\For the $0^{th}$ element,
$$A\b{v_0}t^{k - 1} = \la t^{k - 1}\b{v_0}$$
Considering that $t^{k - 1} \neq 0$ for as long as $t \neq 0$,
$$A\b{v_0} = \la \b{v_0}$$
For the $\a^{th}$ element, 
$$A\b{v_\a} t^{k - 1 - \a} = \la t^{k - 1 - \a}\b{v_\a} +  \l[k - 1 - (\a - 1)\r]t^{k - 2 - (\a - 1)}\b{v_{\a - 1}}$$
$$A\b{v_\a} t^{k - 1 - \a} = \la t^{k - 1 - \a}\b{v_\a} +  \l[k - \a \r]t^{k - 1 - \a}\b{v_{\a - 1}}$$
For as long as $t\neq 0$,  $t^{k - 1- \a}\neq 0$. Therefore, 
$$A\b{v_\a} = \la \b{v_\a} +  \l[k - \a \r]\b{v_{\a - 1}}$$
$$\f{1}{\l[k - \a \r]} (A - \la I)\b{v_\a} = \b{v_{\a - 1}}$$
\\By applying definition recursively,
$$\f{1}{\dst{\prod_{i = 0}^{j - 1}\l[k - i \r]}} (A - \la I)^j \b{v_\a} = \b{v_{\a - j}}$$
For when $j = \a$,
$$\f{1}{\dst{\prod_{i = 0}^{\a - 1}\l[k - i \r]}} (A - \la I)^\a \b{v_\a} = \b{v_{0}}$$
%Seperator
%Seperator
\subsection{Simple First Order Non-Homogenous System}
Suppose, for a non-homogeneous dynamical system, $x' = Ax + k$. The non-homogenous dynamical system could be reduced to a homogenous dynamical system, $y' = Ay$ by an appropriate substitution shown below:  
$$y_1 = x_1 + c_1 \qquad y_2 = x_2 + c_2 \qquad \dots \qquad y_n = x_n + c_n $$
\\wherein $c_1, c_2, c_3 \dots c_n$ are constants
$$y_1' = x_1' \qquad y_2' = x_2' \qquad \dots \qquad y_n' = x_n'$$
\\Let the columns of matrix $A$ be denoted as $a_1, a_2, a_3,\dots a_n$
$$A = \begin{bmatrix} \b{a_1} & \b{a_2} &\dots & \b{a_n} \end{bmatrix}$$
$$Ay = \begin{bmatrix} \b{a_1} & \b{a_2} &\dots & \b{a_n} \end{bmatrix} \begin{bmatrix}y_1 \\ y_2 \\ \vdots \\ y_n \end{bmatrix}$$
$$Ay = \sum_{i = 1} ^ {n} \l[\b{a_i}y_i\r]$$
$$Ay = \sum_{i = 1} ^ {n} \l[\b{a_i}(x_i +c_i)\r]$$
$$Ay = \sum_{i = 1} ^ {n} \l[\b{a_i}x_i + \b{a_i}c_i\r]$$
$$Ay = \sum_{i = 1} ^ {n} \l[\b{a_i}x_i\r] + \sum_{i = 1} ^ {n} \l[\b{a_i}c_i\r]$$
$$Ax + k= \begin{bmatrix} \b{a_1} & \b{a_2} &\dots & \b{a_n} \end{bmatrix} \begin{bmatrix}x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix} + \begin{bmatrix} k_1 \\k_2 \\\vdots \\k_n\end{bmatrix}$$
$$Ax + k = \sum_{i = 1}^{n} \l[\b{a_i}x_i\r] + k$$
$$Ay = Ax + k$$
$$\sum_{i = 1} ^ {n} \l[\b{a_i}x_i\r] + \sum_{i = 1} ^ {n} \l[\b{a_i}c_i\r] = \sum_{i = 1}^{n} \l[\b{a_i}x_i\r] + k$$
$$\sum_{i = 1} ^ {n} \l[\b{a_i}c_i\r] =  k$$
The system above is equivalent to an augmented matrix whose first column until nth column is the columns of the matrix A and its last column is the column vector k. Therefore, the augmented matrix is written below:
$$\begin{matrix}c_1 & c_2 & \dots & c_n& K \end{matrix}$$
$$\begin{bmatrix} \b{a_1} & \b{a_2} & \dots &\b{a_n} &k \end{bmatrix}$$
\\The solution to the augmented matrix will be the values for the constants $c_1,c_2,\dots,c_n$ that would be used in the substitution process in transforming the non-homogenous dynamical system into a homogenous dynamical system. The augmented matrix above would only have a solution for all k in $\mathbb{R}^{n}$ if the matrix A is invertible. If the matrix A is non-invertible , then k must be in $col[A]$, otherwise, then the augmented system forms an inconsistent system. In otherwords, a substitution with the above methods may not exist for an aribtrary choice of $n\times n$ matrix A and arbitrary column vector k. 
%Seperator
%Seperator
\subsection{Simple Higher Order System}
Suppose the dynamical system follows the expression $\dst{\overset{m}{x} = Ax}$, a similar technique with eigenvalues and eigenvectors may be employed along with the roots of unity. By conjecture, the partial solution to the dynamical system $\dst{\overset{m}{x} = Ax}$ follows
$$x_p = \b{v_i}e^{\a_i t}$$
$$\dot{x_p} = \a_i\b{v_i}e^{\a_i t}$$
$$\ddot{x_p} = \a_i^2\b{v_i}e^{\a_i t}$$
$$\overset{m}{x_p} = \a_i^m\b{v_i}e^{\a_i t}$$
$$Ax_p = \overset{m}{x_p}$$
$$A \b{v_i}e^{\a_i t}= \a_i^m\b{v_i}e^{\a_i t}$$
$$A \b{v_i}= \a_i^m\b{v_i}$$
\\Since $\dst{A \b{v_i}= \a_i^m\b{v_i}}$ wherein $\dst{\la_i}$ are eigenvalues of $A$, then $\la_i = \a_i^m$. Since $\la_i$ may be a complex number, $\a_i$ must be the roots of unity to the complex number $\la_i$. If $\la_i = a+bi$
$$\a_n = (a^2 + b^2)^{\f{1}{2m}}cis\l[\f{1}{m}arctan\l(\f{b}{a}\r) + \f{2 \pi n}{m}\r]$$
The general solution to the problem must be the linear combination of the partial solutions $\dst{\sum_{i = 1}^m\l[c_i\b{v_i}e^{\a_{in} t}\r]}$ wherein $c_i$ are constants determined by the initial conditions and $\a_{in}$ represents the $n^{th}$ root of unity of the $i^{th}$ eigenvalue albeit complex or real. 
% Next Section of Problem
%Seperator
\subsection{Simple $n^{th}$ Order Homogenous System}
Suppose the differential equation follows the expression:
$$0 = \sum_{i = 0}^{m}{[A_i \overset{i}{x}]} = A_0 x + A_1 \dot{x} + A_2 \ddot{x}+ \dots + A_{i - 1} \overset{i -  1}{x} + A_{i} \overset{i}{x}$$
\\The general solution to the system above is a linear combination of the partial solutions, $\dst{x(t) = \sum_{j = 1}^{n}{[c_j \b{v_j}e^{\la_j t}]}}$ wherein partial solutions are defined as $\dst{x_{partial}(t) = c_j \b{v_j}e^{\la_j t}}$ and $c_1, c_2 \dots c_n$ are constants determined by the initial value of the problem. 
$$x_{p}(t) = c_j \b{v_j}e^{\la_j t}$$
$$\overset{k}{x_{p}(t)} = c_j \b{v_j}\la_{j}^k e^{\la_j t}$$
$$0 = \sum_{i = 0}^{m}{[A_i \b{v_j} c_j \la_{j}^i e^{\la_j t}]} =A_0 \b{v_j} c_j e^{\la_j t} + A_1 \b{v_j} c_j \la_{j} e^{\la_j t} + \dots + A_m \b{v_j} c_j \la_{j}^m e^{\la_j t}$$
\\For the non-trivial solutions to the homoegenous system of differential equations, $\dst{c_j, \b{v_j}, \la_j \neq 0}$. The function $\dst{e^{\la_j t}}\neq 0$ for all time. Therefore, 
$$0 = \l\{ \sum_{i = 0}^{m}{[A_i \la_{j}^i]} \r\} \b{v_j}$$
\\For $\dst{\b{v_j} \neq 0}$, the matrix $\dst{\sum_{i = 0}^{m}{[A_i \la_{j}^i]}}$ must be non-invertible. Therefore, $\dst{det\l\{ \sum_{i = 0}^{m}{[A_i \la_{j}^i]} \r\} = 0}$
\\The expressions for $\dst{\la_j ^ i}$ could be substituted to the expression $\dst{A_i \la_{j}^i} \b{v_j} = 0$ to express vector $\dst{\b{v_j}}$ explicitly.
%Seperator
%Seperator
%Seperator
\section{Fourier Series}
\begin{comment}
Fourier Transform Header
The Fourier Series in Trigonometric form,
$$f(t) = \f{1}{2}a_0 + \sum_{n = 1}^{\infty}\l[a_n \cos\l(\f{n\pi}{L}t\r) + b_n \sin\l(\f{n\pi}{L}t\r)\r]$$
\end{comment}
\subsection {Definition of Inner Product}
Let f and h be complex valued vectors,
$$f = \begin{bmatrix}f_1\\f_2\\\vdots \\f_n \end{bmatrix}\quad,\quad h = \begin{bmatrix}h_1\\h_2\\\vdots \\h_n \end{bmatrix}$$
The inner product is formally defined as:
$$(f,h) = \sum_{k = 1}^{n}\l[f_k\bar{h_k}\r]$$
wherein $\b{h_k}$ represents the complex conjugate of the $k^{th}$ element of the vector $h$. There are some properties of the inner product:
$$(f,h) = \overline{(h,f)}\quad,\quad (\a f + \be g,h) = \a(f,h) + \be(g,h) \quad,\quad (f,f)\geq0$$
$(f,f) = 0$ if and only if $f_k = 0$ for all $k$ of the vector elements. The magnitude of $n^{th}$ dimensional vectors:
$$\norm{f} = \l(\sum_{k = 1}^{n}|f_k|^2\r)^{\f{1}{2}}$$
%Seperator
%Seperator
\subsection {Definition of Lebesgue Space}
A function would be in Lebesgue space if
$$\int^{\tau}_{0}|f(t)|^2dt < \infty$$
The inner product of a function on the Lebesgue space $L^2(0,\tau)$:
$$(f,g) = \f{1}{\tau}\int^{\tau}_{0}f(t)\overline{g(t)}dt$$
The norm of a function in Lebesgue space:
$$\norm{f} = \l[\f{1}{\tau}\int^{\tau}_{0}|f(t)|^2dt\r]^\f{1}{2}$$
Therefore, it follows that 
$$\norm{f}^2 = (f,f) = \f{1}{\tau}\int^{\tau}_{0}|f(t)|^2dt$$
Distance between two functions defined in Lebesgue space:
$$\norm{f - g} = \l[\f{1}{\tau}\int^{\tau}_{0}|f(t) - g(t)|^2dt\r]^\f{1}{2}$$
%Seperator
%Seperator
\subsection{Exponential Fourier Series}
Fourier series in exponential form:
$$f(t) = \sum^{\infty}_{k = -\infty}\l[a_ke^{-ik\w_0t}\r]$$
wherein $k$ represent integers and the coefficients $a_k$ could be found by,
$$a_k = \f{1}{\tau}\int^{\tau}_{0}e^{ik\w_0t}f(t)dt$$
wherein $\w_0 = 2\pi/\tau$. An orthonormal set in Lebesgue space is defined as a collection of functions that are orthonormal to each other in Lebesgue space and have a magnitude of one. The proof below shows that the complex exponential $e^{ik\w_0t}$ forms an orthonormal set. If two functions are orthogonal, then their inner products in Lebesgue space must be zero.
$$(f,g) = \f{1}{\tau}\int^{\tau}_{0}f(t)\overline{g(t)}dt$$
Substituting for the complex exponential functions, $f(t) = e^{-ik_1\w_0t}\quad,\quad g(t) = e^{-ik_2\w_0t}$,
$$(f,g) = \f{1}{\tau}\int^{\tau}_{0}e^{-ik_1\w_0t} e^{ik_2\w_0t}dt = \f{1}{\tau}\int^{\tau}_{0}e^{i(k_2-k_1)\w_0t}dt$$
For the case wherein $k_2 = k_1$, 
$$(f,g) = \f{1}{\tau}\int^{\tau}_{0}1dt = \f{1}{\tau} \l[t\r]^{\tau}_{0} = \f{1}{\tau}(\tau) = 1$$
Using the previous definition of function magnitudes in Lebesgue space, $\norm{f}^2 = (f,f)\quad,\quad\norm{f} = \sqrt{(f,f)}$. Therefore, $\norm{f} = 1$ which shows that the complex exponential function has a magnitude of $1$ in Lebesgue space. For the case wherein $k_2 \neq k_1$, the subtraction of the two integers yields another non-zero integer.
$$(f,g) = \f{1}{\tau}\int^{\tau}_{0} \cos\l[(k_2-k_1)\w_0t\r] + i\sin\l[(k_2-k_1)\w_0t\r]dt$$
$$(f,g) = \f{1}{\tau(k_2-k_1)\w_0}\l\{\sin\l[(k_2-k_1)\w_0t\r] - i\cos\l[(k_2-k_1)\w_0t\r]\r\}^{t = \tau}_{t = 0}$$
Substituting for $\dst{\w_0 = \f{2\pi}{\tau}}$ 
$$\l\{\sin\l[\f{2\pi(k_2-k_1)t}{\tau}\r]\r\}^{t = \tau}_{t = 0} = \sin\l[2\pi(k_2-k_1)\r] - \sin\l[0\r] = 0$$
$$\l\{\cos\l[\f{2\pi(k_2-k_1)t}{\tau}\r]\r\}^{t = \tau}_{t = 0} = \cos\l[2\pi(k_2-k_1)\r] - \cos\l[0\r] = 1 - 1 = 0$$
Therefore, for the case wherein $k_2 \neq k_1$, $(f,g) = 0$. This shows that complex exponentials are form an orthogonal set in Lebesgue space. Since $e^{ik\w_0t}$ forms an orthonormal set, $e^{ik\w_0t}$ could be used as a basis to represent any function that is in Lebesgue space. The proof below shows the method to find the complex coefficients $a_k$ for an arbitrary function $f(t)$ in Lebesgue space.
$$f(t) = \sum^{\infty}_{k = -\infty}\l[a_ke^{-ik\w_0t}\r]$$
For some particular integer $k_2$,
$$\f{1}{\tau}\int^{\tau}_{0}e^{ik_2\w_0t}f(t)dt= \f{1}{\tau}\int^{\tau}_{0}e^{ik_2\w_0t}\sum^{\infty}_{k = -\infty}\l[a_ke^{-ik\w_0t}\r]dt = \sum^{\infty}_{k = -\infty}\l[\f{a_k}{\tau}\int^{\tau}_{0}e^{-ik\w_0t}e^{ik_2\w_0t}dt\r]$$
The above working is true due to the integral operation being a linear operation. Linear operations are discussed earlier in this document. From the previous findings,
$$(f,g) = \f{1}{\tau}\int^{\tau}_{0}e^{-ik_1\w_0t} e^{ik_2\w_0t}dt = \f{1}{\tau}\int^{\tau}_{0}e^{i(k_2-k_1)\w_0t}dt$$
$(f,g) = 1$ only when $f$ and $g$ are identical to each other. For all other cases, $(f,g) = 0$. Following this, $\dst{\f{1}{\tau}\int^{\tau}_{0}e^{-ik_1\w_0t} e^{ik_2\w_0t}dt} = 1$ only when $k = k_2$, otherwise, $\dst{\f{1}{\tau}\int^{\tau}_{0}e^{-ik_1\w_0t} e^{ik_2\w_0t}dt} = 0$. Therefore,
$$\f{1}{\tau}\int^{\tau}_{0}e^{ik_2\w_0t}f(t)dt = \sum^{\infty}_{k = -\infty}\l[a_k\times\f{1}{\tau}\int^{\tau}_{0}e^{-ik\w_0t}e^{ik_2\w_0t}dt\r] = a_k$$
%Seperator
%Seperator
\subsection{Trigonometric Fourier Series}
Any arbitrary function $f(t)$ with a periodicity of $L$ could be expressed as a linear combination of sinusoids of varying frequencie. $a_n$ and $b_n$, but $n$ are integers $n = 1,2,3,4\dots$. The abritrary function $f(t)$ expressed as a linear combination of trigonometric functions:
$$f(t) = \f{1}{2}a_0 + \sum_{n = 1}^{\infty}\l[a_n \cos\l(\f{n\pi}{L}t\r) + b_n \sin\l(\f{n\pi}{L}t\r)\r]$$
The three equations below is correct and serves as a method to find coefficients $a_0$, $a_n$ and $b_n$,
$$a_0 = \f{1}{L}\int_{-L}^{L}f(t)dt$$
$$a_n = \f{1}{L}\int_{-L}^{L}f(t)\cos\l(\f{n\pi}{L}t\r)dt$$
$$b_n = \f{1}{L}\int_{-L}^{L}f(t)\sin\l(\f{n\pi}{L}t\r)dt$$
The proof of each of the three equations is showb. Below is written the list of trigonometric identities relating multiplication of trigonometric functions of differing frequencies that will be important for the proof:
$$2\cos(\t)\cos(\ph) = \cos(\t - \ph) + \cos(\t + \ph)$$ 
$$2\sin(\t)\sin(\ph) = \cos(\t - \ph) - \cos(\t + \ph)$$
$$2\sin(\t)\cos(\ph) = \sin(\t + \ph) + \sin(\t - \ph)$$
For coefficient $a_0$,
$$\int_{-L}^{L}f(t)dt = \f{1}{2} \int_{-L}^{L}a_0dt + \sum_{n = 1}^{\infty}\l[a_n \int_{-L}^{L}\cos\l(\f{n\pi}{L}t\r)dt + b_n \int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)dt\r]$$
$$\f{1}{2} \int_{-L}^{L}a_0dt = \f{1}{2}a_0\times2L$$
$$\f{1}{2} \int_{-L}^{L}a_0dt = a_0L$$
$$\int_{-L}^{L}\cos\l(\f{n\pi}{L}t\r)dt = \f{L}{n\pi}\l[\sin\l(\f{n\pi}{L}t\r)\r]^{t = L}_{t = -L}$$
$$\int_{-L}^{L}\cos\l(\f{n\pi}{L}t\r)dt = \f{L}{n\pi}\l[\sin\l(n\pi\r) - \sin\l(-n\pi\r)\r]$$
Considering that $n$ is an integer, $\sin\l(n\pi\r) = \sin\l(-n\pi\r) = 0$. Therefore, 
$$\int_{-L}^{L}\cos\l(\f{n\pi}{L}t\r)dt = 0$$
By similar reasoning, it could be seen that $\dst{\int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r) = 0}$, but the integral is evaluated below anyways,
$$\int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)dt = -\f{L}{n\pi}\l[\cos\l(\f{n\pi}{L}t\r)\r]^{t = L}_{t = -L}$$
$$\int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)dt = -\f{L}{n\pi}\l[\cos\l(n\pi\r) - \cos\l(-n\pi\r)\r]$$
By the even property of the cosine function, $\cos(\t) = \cos(-\t)$. Therefore,
$$\int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)dt = -\f{L}{n\pi}\l[\cos\l(n\pi\r) - \cos\l(n\pi\r)\r]$$
$$\int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)dt = 0$$
By reiterating the integration of $f(t)$ from $t = -L$ until $t = L$
$$\int_{-L}^{L}f(t)dt = a_0L + \sum_{n = 1}^{\infty}\l[a_n\times 0 + b_n \times 0\r]$$
$$\int_{-L}^{L}f(t)dt = a_0L$$
$$a_0 = \f{1}{L}\int_{-L}^{L}f(t)dt$$
For coefficient $a_n$, let $m$ be some particular integer, either $1$, $2$, or $3$. For some of the terms of the Fourier Series, $m = n$. However, for all other terms, $m\neq n$.
\begin{align*}
\int_{-L}^{L}f(t)\cos\l(\f{m\pi}{L}t\r)dt = &\sum_{n = 1}^{\infty}\l[a_n \int_{-L}^{L}\cos\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r)dt + b_n \int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r)dt\r] \\ &+ \f{1}{2}a_0 \int_{-L}^{L}\cos\l(\f{m\pi}{L}t\r)dt
\end{align*}
$$2\cos\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r) = \cos\l[\f{(n-m)\pi}{L}t\r] + \cos\l[\f{(n+m)\pi}{L}t\r]$$
$$\cos\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r) = \f{1}{2}\cos\l[\f{(n-m)\pi}{L}t\r] + \f{1}{2}\cos\l[\f{(n+m)\pi}{L}t\r]$$
$$\int_{-L}^{L}\cos\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r)dt = \f{1}{2}\int_{-L}^{L}\cos\l[\f{(n-m)\pi}{L}t\r]dt + \f{1}{2}\int_{-L}^{L}\cos\l[\f{(n+m)\pi}{L}t\r]dt$$
Consider the case wherein $m = n$,
$$\int_{-L}^{L}\cos^2\l(\f{n\pi}{L}t\r)dt = \f{1}{2}\int_{-L}^{L}\cos\l(\f{2n\pi}{L}t\r) + 1dt$$
$$\int_{-L}^{L}\cos^2\l(\f{n\pi}{L}t\r)dt = \f{1}{2}\l[\f{L}{2n\pi}\sin\l(\f{2n\pi}{L}t\r) + t\r]^{t = L}_{t = -L}$$
$$\int_{-L}^{L}\cos^2\l(\f{n\pi}{L}t\r)dt = \f{1}{2}\l[\f{L}{2n\pi}\l(\sin\l(2n\pi\r) - \sin\l(-2n\pi\r)\r) + 2L\r]$$
$$\int_{-L}^{L}\cos^2\l(\f{n\pi}{L}t\r)dt = \f{1}{2}\l[2L\r] = L$$
Consider the case wherein $m\neq n$,
\begin{align*}
\int_{-L}^{L}\cos\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r)dt = & \f{L}{2(n-m)\pi}\l\{\sin\l[\f{(n-m)\pi}{L}t\r]\r\}_{t = -L}^{t = L} \\ & + \f{L}{2(n+m)\pi}\l\{\sin\l[\f{(n+m)\pi}{L}t\r]\r\}_{t = -L}^{t = L}
\end{align*}
By similar argument mentioned previously that sine of a multiple of $\pi$ yields $0$, then
$$\int_{-L}^{L}\cos\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r)dt = 0$$
For the second term in the summation notation,
$$2\sin\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r) = \sin\l[\f{(n+m)\pi}{L}t\r] + \sin\l[\f{(n-m)\pi}{L}t\r]$$
$$\sin\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r) = \f{1}{2}\sin\l[\f{(n+m)\pi}{L}t\r] + \f{1}{2}\sin\l[\f{(n-m)\pi}{L}t\r]$$
$$\int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r)dt = \f{1}{2}\int_{-L}^{L}\sin\l[\f{(n+m)\pi}{L}t\r]dt + \f{1}{2}\int_{-L}^{L}\sin\l[\f{(n-m)\pi}{L}t\r]dt$$
For the case wherein $m\neq n$,
\begin{align*}
\int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r)dt = &-\f{L}{2(n+m)\pi}\l\{\cos\l[\f{(n+m)\pi}{L}t\r]\r\}_{t = -L}^{t = L} \\ & - \f{L}{2(n-m)\pi}\l\{\cos\l[\f{(n-m)\pi}{L}t\r]\r\}_{t = -L}^{t = L}
\end{align*}
Since $\cos(x)$ is an even function, the integral evaliuates to 0. Therefore,
$$\int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r)dt = 0$$
For the case wherein $m = n$, the second sine function is irrelevant because $\sin(0) = 0$, due to $n-m=0$. The following is just a degenerate case of the case wherein $m\neq n$.
$$\int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r)dt = \f{1}{2}\int_{-L}^{L}\sin\l[\f{(n+m)\pi}{L}t\r]dt$$
Since the integral above is just a degenerate case of $m\neq n$, then the integral just evaluates to $0$. Therefore,
$$\int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)\cos\l(\f{n\pi}{L}t\r)dt = 0$$
For coefficient $b_n$,
$$\int_{-L}^{L}f(t)dt = \f{1}{2} \int_{-L}^{L}a_0dt + \sum_{n = 1}^{\infty}\l[a_n \int_{-L}^{L}\cos\l(\f{n\pi}{L}t\r)dt + b_n \int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)dt\r]$$
For the final term in the expression describing the integral of $\dst{f(t)\cos\l(\f{n\pi}{L}t\r)}$, 
$$\int_{-L}^{L}\cos\l(\f{m\pi}{L}t\r)dt = \f{L}{m\pi}\l[\sin\l(\f{m\pi}{L}t\r)\r]^{t=L}_{t=-L}$$
Since $m$ is an integer,
$$\int_{-L}^{L}\cos\l(\f{m\pi}{L}t\r)dt = 0$$
A reiteration of the integral of $\dst{f(t)\cos\l(\f{n\pi}{L}t\r)}$,
 \begin{align*}
\int_{-L}^{L}f(t)\cos\l(\f{m\pi}{L}t\r)dt = &\sum_{n = 1}^{\infty}\l[a_n \int_{-L}^{L}\cos\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r)dt + b_n \int_{-L}^{L}\sin\l(\f{n\pi}{L}t\r)\cos\l(\f{m\pi}{L}t\r)dt\r] \\ &+ \f{1}{2}a_0 \int_{-L}^{L}\cos\l(\f{m\pi}{L}t\r)dt
\end{align*}
By substituing all the known parts from the previous workings, 
$$\int_{-L}^{L}f(t)\cos\l(\f{m\pi}{L}t\r)dt = a_m L$$
wherein $m = n$. Therefore,
$$a_m = \f{1}{L}\int_{-L}^{L}f(t)\cos\l(\f{m\pi}{L}t\r)dt$$
for $n=1,2,3\dots$
$$a_n = \f{1}{L}\int_{-L}^{L}f(t)\cos\l(\f{n\pi}{L}t\r)dt$$
The proof for the coefficient $b_n$ could be done in a similar way as for the coefficient $a_n$. These two coefficients are analogous to each other.
%Seperator
%Seperator
\subsection{Discrete Fourier Transform}
The usage of the Discrete Fourier Transform Matrix is given below.
$$\begin{bmatrix}p(t_0) \\ p(t_1) \\ p(t_2 )\\ \vdots \\ p(t_{v-3}) \\ p(t_{v-2}) \\ p(t_{v-1}) \end{bmatrix} = 
\begin{bmatrix}
 1 && 1 && 1 && 1 && \cdots && 1 && 1 && 1 \\
 1 && \la_{1}^{1} && \la_{1}^{2} && \la_{1}^{3} && \cdots && \la_{1}^{-3} && \la_{1}^{-2} && \la_{1}^{-1} && \\
 1 && \la_{2}^{1} && \la_{2}^{2} && \la_{2}^{3} && \cdots && \la_{2}^{-3} && \la_{2}^{-2} && \la_{2}^{-1} && \\
 \vdots && \vdots && \vdots && \vdots && \cdots && \vdots && \vdots && \vdots && \\
 1 && \la_{v-3}^{1} && \la_{v-3}^{2} && \la_{v-3}^{3} && \cdots && \la_{v-3}^{-3} && \la_{v-3}^{-2} && \la_{v-3}^{-1} && \\
 1 && \la_{v-2}^{1} && \la_{v-2}^{2} && \la_{v-2}^{3} && \cdots && \la_{v-2}^{-3} && \la_{v-2}^{-2} && \la_{v-2}^{-1} && \\
 1 && \la_{v-1}^{1} && \la_{v-1}^{2} && \la_{v-1}^{3} && \cdots && \la_{v-1}^{-3} && \la_{v-1}^{-2} && \la_{v-1}^{-1} && \\
\end{bmatrix}
\begin{bmatrix} a_{0} \\ a_{1} \\ a_{2} \\ \vdots \\ a_{-3} \\ a_{-2} \\ a_{-1} \end{bmatrix} $$
%Seperator
%Seperator
\subsection{Higher-Dimensional Fourier Series}
The Fourier Series in complex exponential form,
$$f(t) = \sum^{\infty}_{k_i = -\infty}\l[a_{k_i}e^{-ik_i\w_{k_i}t}\r]\quad,\quad \w_{k_i} = 2\pi/\tau_{k_i}$$
wherein $k_i$ represent integers. Let the two-dimensional Fourier Series be defined as the total expression of a Fourier Series nested in the coefficients of another Fourier Series,
$$f_2(x_1,x_2) = \sum^{\infty}_{k_1 = -\infty}\l[\sum^{\infty}_{k_2 = -\infty}\l(a_{k_1,\,k_2}e^{-ik_2\w_{k_2}x_2}\r)e^{-ik_1\w_{k_1}x_1}\r] = \sum^{\infty}_{k_1 = -\infty}\sum^{\infty}_{k_2 = -\infty}\l(a_{k_1,\,k_2}e^{-ik_2\w_{k_2}x_2}e^{-ik_1\w_{k_1}x_1}\r)$$
$$f_2(x_1,x_2) = \sum^{\infty}_{k_1 = -\infty}\sum^{\infty}_{k_2 = -\infty}\l[a_{k_1,\,k_2}e^{-i(k_1\w_{k_1}x_1+k_2\w_{k_2}x_2)}\r]$$
wherein the natural frequency $\w$ are defined as,
$$\w_{k_1} = 2\pi/\tau_{k_1} \quad,\quad \w_{k_2} = 2\pi/\tau_{k_2}$$
wherein $\tau_{k_1}$ represent the outer Fourier interval, and $\tau_{k_2}$ represent the inner Fourier interval. Therefore, generalizing to $n$ dimensions,
$$f_m(x_1,x_2,\dots,x_n) = \prod^{n}_{m=1}\l\{\sum^{\infty}_{k_m = -\infty}\l[a_{k_1,\,k_2,\dots,k_n}e^{-i\l[\sum^{n}_{r=1}\l(k_r\w_{k_r}x_r\r)\r]}\r]\r\}$$
wherein $\dst{\prod^{n}_{m=1}\l[\sum^{\infty}_{k_m = -\infty}(obj)\r]}$ represents $n$ summations of mathematiical objects nested in each other. The expression above does not represent consecutive multiplications of the product notation. The product notation is just used to represent summation notations placed side by side and implemented consecutively in any order. 
%Seperator
%Seperator
%Seperator
\section{Laplace Transform}
\begin{comment}
Laplace Transform Header
\end{comment}
\subsection{Definition of Laplace Transform}
Laplace Transform is defined as the following,
$$\lap[f(t)] = \int^{\infty}_{0}e^{-st}f(t)\,dt = F(s)$$
The Laplace Transform is a linear transform since the integral and product operations are both linear operations as well.
$$\lap[\a f(t)] = \a\lap[f(t)]\quad,\quad\lap[f(t) + g(t)] = \lap[f(t)] + \lap[g(t)]$$
$$\lap[\a f(t) + \be g(t)] = \a\lap[f(t)] + \be\lap[g(t)]$$
wherein $\a$, $\be$ represent constants and $f(t)$, $g(t)$ represent functions of t.
%Seperator
%Seperator
\subsection{Transforms of Derivatives}
In General form,
$$\lap[\overset{n}{f(t)}] = s^n\lap[f(t)] - \sum^{n - 1}_{k = 0}\l[s^{n - 1 - k}\overset{k}{f(0)}\r]$$
wherein $\overset{n}{f(t)}$ represents the $n^{th}$ derivative of the function $f(t)$. Proof is shown below,
$$\lap[\overset{n}{f(t)}] = \int^{\infty}_{0}e^{-st}\overset{n}{f(t)}\,dt$$
$$\int uv' \,dt = uv - \int u'v \,dt$$
$$u = e^{-st}\quad,\quad u' = -se^{-st} \quad,\quad v' = \overset{n}{f(t)} \quad,\quad v = \overset{n-1}{f(t)}$$
$$\lap[\overset{n}{f(t)}] = \int^{\infty}_{0}e^{-st}\overset{n}{f(t)}dt = \l[e^{-st}\overset{n-1}{f(t)}\r]^{\infty}_{0} - \int^{\infty}_{0}-se^{-st}\overset{n-1}{f(t)} \,dt = -\overset{n-1}{f(0)} + s\int^{\infty}_{0}e^{-st}\overset{n-1}{f(t)} \,dt $$
Generalizing for the second integral term,
$$\int^{\infty}_{0}e^{-st}\overset{n-i}{f(t)} \,dt = \l[e^{-st}\overset{n-1-i}{f(t)}\r]^{\infty}_{0} + s\int^{\infty}_{0}e^{-st}\overset{n-1-i}{f(t)} \,dt = -\overset{n-1-i}{f(0)} + s\int^{\infty}_{0}e^{-st}\overset{n-1-i}{f(t)} \,dt$$
By applying substitution recursively,
$$\lap[\overset{n}{f(t)}] = -\sum^{k}_{i = 0}\l[s^i\overset{n-1-i}{f(0)}\r] + \prod^{k}_{i = 0}\l[s\r]\int^{\infty}_{0}e^{-st}\overset{n-1-k}{f(t)} \,dt = -\sum^{k}_{i = 0}\l[s^i\overset{n-1-i}{f(0)}\r] + s^{k + 1}\int^{\infty}_{0}e^{-st}\overset{n-1-k}{f(t)} \,dt$$
Substituting the value for $k = n-1$,
$$\lap[\overset{n}{f(t)}] = -\sum^{n-1}_{i = 0}\l[s^i\overset{n-1-i}{f(0)}\r] + s^{n}\int^{\infty}_{0}e^{-st}f(t) \,dt$$
A few things should be noted,
$$\int^{\infty}_{0}e^{-st}f(t) \,dt = \lap[f(t)]\quad,\quad \sum^{n-1}_{i = 0}\l[s^i\overset{n-1-i}{f(0)}\r] = \sum^{n-1}_{i = 0}\l[s^{n-1-i}\overset{i}{f(0)}\r]$$
By substitution of the counting variable $i$ with $k$,
$$\lap[\overset{n}{f(t)}] = -\sum^{n-1}_{i = 0}\l[s^i\overset{n-1-i}{f(0)}\r] + s^{n}\int^{\infty}_{0}e^{-st}f(t) \,dt = s^n \lap[f(t)] + \sum^{n-1}_{k = 0}\l[s^{n-1-k}\overset{k}{f(0)}\r]$$
%Seperator
%Seperator
\subsection{Transforms of Integrals}
$$\lap\l[\int^{t}_{0}f(\tau)d\tau\r] = \f{1}{s}\lap[f(t)]$$
$$\lap\l[\int^{t}_{0}f(\tau)d\tau\r] = \int^{\infty}_{0}e^{-st}\int^{t}_{0}f(\tau)d\tau\,dt$$
$$\int uv' \,dt = uv - \int u'v \,dt$$
$$u = \int^{t}_{0}f(\tau)d\tau \quad,\quad u' = f(t) \quad,\quad v' = e^{-st} \quad,\quad v = -\f{1}{s}e^{-st}$$
$$\int^{\infty}_{0}e^{-st}\int^{t}_{0}f(\tau)d\tau\,dt = -\l[\f{1}{s}e^{-st}\int^{t}_{0}f(\tau)d\tau\r]^{\infty}_{0} + \int^{\infty}_{0}\f{1}{s}e^{-st}f(t)\,dt$$
It should be noted that since the function $f(t)$ is in exponential order,
$$\l[\f{1}{s}e^{-st}\int^{t}_{0}f(\tau)d\tau\r]^{\infty}_{0} = 0$$
Substituting the $uv$ term with zero,
$$\int^{\infty}_{0}e^{-st}\int^{t}_{0}f(\tau)d\tau\,dt = \int^{\infty}_{0}\f{1}{s}e^{-st}f(t)\,dt = \f{1}{s}\int^{\infty}_{0}e^{-st}f(t)\,dt = \f{1}{s}\lap[f(t)]$$
%Seperator
%Seperator
\subsection{Derivative of Transforms}
$$\lap[t^nf(t)] = (-1)^n\overset{n}{F(s)} = (-1)^n\f{d^n}{ds^n}\l\{\lap[f(t)]\r\}$$
wherein $F(s)$ represents the laplace transform of the function $f(t)$. By the definition of Laplace Transforms discussed earlier,
$$\lap[t^nf(t)] = \int^{\infty}_{0}e^{-st}t^nf(t)\,dt\quad,\quad F(s) = \lap[f(t)] = \int^{\infty}_{0}e^{-st}f(t)\,dt$$
Differentiating the Laplace Transform of $f(t)$ with respect to $s$ iteratively $n$ times,
$$\overset{n}{F(s)} = \f{d^n}{ds^n}\{\lap[f(t)]\} = \f{d^n}{ds^n}\int^{\infty}_{0}e^{-st}f(t)\,dt = (-1)^n\int^{\infty}_{0}e^{-st}t^n f(t)\,dt$$
$$(-1)^n\overset{n}{F(s)} = \int^{\infty}_{0}e^{-st}t^n f(t)\,dt$$
By substituting the definition for the Laplace Transform of $\dst{t^nf(t)}$,
$$(-1)^n\overset{n}{F(s)} = \lap[t^nf(t)]$$
%Seperator
%Seperator
\subsection{Integration of Transforms}
$$\lap\l[\f{f(t)}{t}\r] = \int^{\infty}_{s}F(\tau)\,d\tau$$
wherein $F(s)$ represents the laplace transform of the function $f(t)$.
$$\lap\l[\f{f(t)}{t}\r] = \int^{\infty}_{0}\f{e^{-st}f(t)}{t}\,dt\quad,\quad F(s) = \lap[f(t)] = \int^{\infty}_{0}e^{-st}f(t)\,dt$$
$$\int^{\infty}_{s}F(\tau)\,d\tau = \int^{\infty}_{s}\int^{\infty}_{0}e^{-\tau t}f(t)\,dt\,d\tau = \int^{\infty}_{0}\int^{\infty}_{s}e^{-\tau t}f(t)\,d\tau\,dt = \int^{\infty}_{0}\l[-\f{1}{t}e^{-\tau t}f(t)\r]^{\tau = \infty}_{\tau = s}\,dt$$
$$\int^{\infty}_{s}F(\tau)\,d\tau = -\int^{\infty}_{0}\f{f(t)}{t}\l[e^{-\tau t}\r]^{\tau = \infty}_{\tau = s}\,dt = -\int^{\infty}_{0}\f{f(t)}{t}\l[\lim_{\tau\to\infty}(e^{-\tau t}) - e^{-s t}\r]\,dt$$
Taking into account that, $\dst{\lim_{\tau\to\infty}(e^{-\tau t})} = 0,$
$$\int^{\infty}_{s}F(\tau)\,d\tau = -\int^{\infty}_{0}\f{f(t)}{t}\l[- e^{-s t}\r]\,dt = \int^{\infty}_{0}\f{e^{-s t}f(t)}{t}\,dt$$
By substituting the definition of the laplace transform of $\dst{\f{f(t)}{t}}$,
$$\int^{\infty}_{s}F(\tau)\,d\tau = \lap\l[\f{f(t)}{t}\r]$$
%Seperator
%Seperator
\subsection{Translation of Transforms}
$$\lap\l[u(t-c)f(t)\r] = e^{-cs}\lap\l[f(t+c)\r]$$
By definition of Laplace Transform,
$$\lap\l[u(t-c)f(t)\r] = \int^{\infty}_{0}e^{-st}u(t-c)f(t)\,dt = \int^{\infty}_{c}e^{-st}f(t)\,dt + \int^{c}_{0}e^{-st}\times0\,dt$$
$$\lap\l[u(t-c)f(t)\r] = \int^{\infty}_{c}e^{-st}f(t)\,dt$$
Using the substitution $\dst{t = \tau + c}$. When $\dst{t = \infty\quad,\quad \tau = \infty \quad}$ and when $\dst{t = c\quad,\quad \tau = 0}$. Therefore,
$$\lap\l[u(t-c)f(t)\r] = \int^{t = \infty}_{t = c}e^{-s(\tau + c)}f(\tau + c)\,dt = \int^{\tau = \infty}_{\tau = 0}e^{-s(\tau + c)}f(\tau + c)\,d\tau$$
$$\lap\l[u(t-c)f(t)\r] = \int^{\tau = \infty}_{\tau = 0}e^{-s\tau -sc}f(\tau + c)\,d\tau = \int^{\tau = \infty}_{\tau = 0}e^{-cs}e^{-s\tau}f(\tau + c)\,d\tau$$
Since variables $s$ and $c$ are not changing with time, the term $e^{-cs}$ could be treated as some form of constant. Therefore,
$$\lap\l[u(t-c)f(t)\r] = e^{-cs}\int^{\infty}_{0}e^{-s\tau}f(\tau + c)\,d\tau$$
It should be noted that the change of variables allows,
$$\lap\l[f(t+c)\r] = \int^{\infty}_{0}e^{-st}f(t + c)\,dt = \int^{\infty}_{0}e^{-s\tau}f(\tau + c)\,d\tau$$
By substitution,
$$\lap\l[u(t-c)f(t)\r] = e^{-cs}\lap\l[f(t+c)\r]$$
%Seperator
%Seperator
\subsection{Transforms of Translated Functions}
$$\lap[e^{ct}f(t)] = F(s-c)$$
Reiterating the definition of laplace transforms,
$$\lap[f(t)] = \int^{\infty}_{0}e^{-st}f(t)\,dt = F(s)$$
$$\lap[e^{ct}f(t)] = \int^{\infty}_{0}e^{ct}e^{-st}f(t)\,dt = \int^{\infty}_{0}e^{-st + ct}f(t)\,dt$$
$$\lap[e^{ct}f(t)] = \int^{\infty}_{0}e^{-(s-c)t}f(t)\,dt = F(s-c)$$
%Seperator
%Seperator
\subsection{Convolution}
$$f*g(t) = \int^{t}_{0}f(\tau)g(t - \tau)\,d\tau$$
The convolution is a commutative transformation. Therefore,
$$f*g(t) = g*f(t) = \int^{t}_{0}f(\tau)g(t - \tau)\,d\tau = \int^{t}_{0}g(\tau)f(t - \tau)\,d\tau$$
One useful property of the convolution function,
$$\lap\l[f*g(t)\r] = \lap\l[f(t)\r]\times\lap\l[g(t)\r]$$
wherein
$$F(s) = \lap[f(t)] = \int^{\infty}_{0}e^{-st}f(t)\,dt\quad,\quad G(s) = \lap[g(t)] = \int^{\infty}_{0}e^{-st}g(t)\,dt$$
By a substitution of variables $t = u$ it could be re-written,
$$F(s) = \lap[f(u)] = \int^{\infty}_{0}e^{-su}f(u)\,du\quad,\quad G(s) = \lap[g(u)] = \int^{\infty}_{0}e^{-su}g(u)\,du$$
Examining the Lapalce Transform of $g(u)$, and making the substitution $u = t-\tau$
$$\lap[g(t-\tau)] = \int^{u = \infty}_{u = 0}e^{-s(t-\tau)}g(t-\tau)\,dt$$
When $\dst{u = \infty\quad,\quad t=\infty}\quad$ and when $\quad\dst{u = 0 \quad,\quad t = \tau}$. Therefore,
$$\lap[g(t-\tau)] = \int^{t = \infty}_{t = \tau}e^{-s(t-\tau)}g(t-\tau)\,dt$$
The $\dst{e^{\tau s}}$ term could be isolated because both variables $\tau$ and $s$ in this case are non-changing with $t$. The next form is identical to the laplace transform at the Translation of Transforms subsection,
$$\int^{\tau = \infty}_{\tau = 0}e^{-s(\tau + c)}f(\tau + c)\,d\tau = e^{-cs}\int^{\infty}_{0}e^{-s\tau}f(\tau + c)\,d\tau$$
By substituting $\tau$ in the Translation of Transforms subsection with $t$, substituting $c$ with $-\tau$, and substituting the arbitrary function $g$ with the arbitrary function $f$,
$$\int^{t = \infty}_{t = 0}e^{-s(t -\tau)}g(t -\tau)\,dt = e^{\tau s}\int^{\infty}_{0}e^{-st}g(t - \tau)\,dt$$
Therefore,
$$\lap[g(t-\tau)] = G(s) = e^{\tau s}\int^{\infty}_{0}e^{-st}g(t - \tau)\,dt$$
Proving the Convolution Property by first examining the product of the two Laplace Transforms,
$$F(s)\times G(s) = G(s)\int^{\infty}_{0}e^{-su}f(u)\,du = \int^{\infty}_{0}e^{-su}G(s)f(u)\,du$$
The above would be perfectly legal operations because $G(s)$ is a function in terms of $s$ and is unchanging with respect to variable $t$. Therefore, the function $G(s)$ could be treated as a constant that can be place inside and outside of the integral.
$$F(s)\times G(s) = \int^{\infty}_{0}e^{-s\tau}f(\tau) \times e^{\tau s}\int^{\infty}_{0}e^{-st}g(t - \tau)\,dt\,d\tau$$
$$F(s)\times G(s) = \int^{\infty}_{0}\int^{\infty}_{0}e^{-st}f(\tau)g(t - \tau)\,dt\,d\tau$$
By chaging the order of integration,
$$F(s)\times G(s) = \int^{\infty}_{0}e^{-st}\int^{\infty}_{0}f(\tau)g(t - \tau)\,d\tau\,dt = \lap\l[\int^{\infty}_{0}f(\tau)g(t - \tau)\,d\tau\r]$$
$$F(s)\times G(s) = \lap\l[f*g(t)\r]$$
%Seperator
%Seperator
%Seperator
\section{Gradient Operators}
Given the the arbitrary fucntion $f$,
%Seperator
%Seperator
\subsection{Cartesian Coordinates}
%Seperator
%Seperator
\subsection{Cylindrical Coordinates}
%Seperator
%Seperator
\subsection{Spherical Coordinates}
%Seperator
%Seperator
%Seperator
\section{Partial Differential Equations}
\begin{comment}
Partial Differential Equations Header
Currently, only discussions of the Sturm -Liouville, the other applications are placed elsewhere, such as Physics Archives or Fluid Archives
\end{comment}
The conventional gradient operator in cartesian coordinates is typically defined as,
$$\nabla_{xyz} = \begin{pmatrix}\dst{\f{\p}{\p x}} & \dst{\f{\p}{\p y}} & \dst{\f{\p}{\p z}}\end{pmatrix}^T\quad,\quad \nabla^n_{xyz} = \begin{pmatrix}\dst{\f{\p^n}{\p x^n}} & \dst{\f{\p^n}{\p y^n}} & \dst{\f{\p^n}{\p z^n}}\end{pmatrix}^T$$
Let the modified gradient operator $\dst{({}_{m}\nabla)}$ in cartesian coordinates be defined as,
$${}_{m}\nabla_{xyz} = \begin{pmatrix}\dst{\a_1\f{\p}{\p x}} & \dst{\a_2\f{\p}{\p y}} & \dst{\a_3\f{\p}{\p z}}\end{pmatrix}^T\quad,\quad {}_{m}\nabla^n_{xyz} = \begin{pmatrix}\dst{\be_1\f{\p^n}{\p x^n}} & \dst{\be_2\f{\p^n}{\p y^n}} & \dst{\be_3\f{\p^n}{\p z^n}}\end{pmatrix}^T$$
This modification allows the gradient operator to be more general. The modified gradient operator for $m$ dimensional cartesian coordinates,
$${}_{m}\nabla_{xyz} = \begin{pmatrix}\dst{\a_1\f{\p}{\p x_1}} & \dst{\a_2\f{\p}{\p x_2}} & \dots & \dst{\a_n\f{\p}{\p x_m}}\end{pmatrix}^T\quad,\quad {}_{m}\nabla^n_{xyz} = \begin{pmatrix}\dst{\be_1\f{\p^n}{\p x_1^n}} & \dst{\be_2\f{\p^n}{\p x_2^n}} & \dots & \dst{\be_3\f{\p^n}{\p x_m^n}}\end{pmatrix}^T$$
%Seperator
%Seperator
\subsection{Methods in Generalized Cartesian Coordinates}
$$\f{\p^2u}{\p t^2} + a\f{\p u}{\p t} = {}_{m_1}\nabla^2_{x_1\dots x_q}(u) + {}_{m_2}\nabla_{x_1\dots x_q}(u) = \sum^{q}_{i=1}\l[b_i\,\f{\p^2u}{\p x^2_{i}} + c_i\f{\p u}{\p x_{i}}\r]$$
wherein $\dst{{}_{m_1}\nabla^2_{x_1\dots x_q}(u) = {}_{m_1}\nabla_{x_1\dots x_q} \d \nabla_{x_1\dots x_q}u}$
%Seperator
%Seperator
\subsection{Methods in Cylindrical Coordinates}
$$\f{\p^2u}{\p t^2} + a\f{\p u}{\p t} = {}_{m_1}\nabla^2_{r\t z}(u) + {}_{m_2}\nabla_{r\t z}\d(u) = $$
%Seperator
%Seperator
\subsection{Methods in Spherical Coordinates}
$$\f{\p^2u}{\p t^2} + a\f{\p u}{\p t} = {}_{m_1}\nabla^2_{r\t\ph}(u) + {}_{m_2}\nabla_{r\t\ph}(u) = $$
%Seperator
%Seperator
%Seperator
%Seperator
%Physics Archives
\subsection{Temperature Distribution of Cartesian Slabs}
$$\f{\p u}{\p t} = k\nabla^2_{xy}(u) = k\l[\f{\p^2 u}{\p x^2} + \f{\p^2 u}{\p y^2}\r]$$
%Seperator
%Seperator
%Physics Archives
\subsection{Temperature Distribution of Polar Slabs}
$$\f{\p u}{\p t} = k\nabla^2_{r}(u) = k\l[\f{\p^2 u}{\p r^2} + \f{1}{r}\f{\p u}{\p r}\r]$$
%Seperator
%Seperator
%Structural Archives
\subsection{Longitudinal Structural Bar Vibrations}
$$\f{\p^2 u}{\p t^2} = a^2\f{\p^2 u}{\p x^2}$$
%Seperator
%Seperator
%Structural Archives
\subsection{Transverse Structural Bar Vibrations}
$$\f{\p^2 y}{\p t^2} = -a^4\f{\p^4 y}{\p x^4}$$
%Seperator
%Seperator
%Structural Archives
\subsection{Natural Frequencies of Beams}
$$\f{\p^2 y}{\p t^2} = -a^4\f{\p^4 y}{\p x^4}$$
%Seperator
%Seperator
%Physics Archives
\subsection{Two-Dimensional Wave Equation in Cartesian Coordinates}
$$\f{\p^2u}{\p t^2} = c^2\nabla^2_{xy}(u) = c^2\l[\f{\p^2u}{\p x^2} + \f{\p^2u}{\p y^2}\r]$$
%Seperator
%Seperator
%Physics Archives
\subsection{Two-Dimensional Wave Equation in Polar Coordinates}
$$\f{\p^2u}{\p t^2} = c^2\nabla^2_{r\t}(u) = c^2\l[\f{\p^2u}{\p r^2} + \f{1}{r}\f{\p u}{\p r} + \f{1}{r^2}\f{\p^2u}{\p \t^2}\r]$$
%Seperator
%Seperator
%Physics Archives
\subsection{Spherical Harmonics and Ocean Waves}
$$\f{\p^2u}{\p t^2} = b^2\nabla^2_{\ph\t}(u) = b^2\l\{\f{1}{\sin(\t)}\f{\p}{\p \ph}\l[\sin(\ph)\f{\p u}{\p \ph}\r] + \f{1}{\sin^2(\ph)}\f{\p^2u}{\p \t^2}\r\}$$
%Seperator
%Seperator
%Seperator
\section{Sturm-Liouville Problems}
\begin{comment}
\end{comment}
\subsection{Definition of Stum-Liouville Problems}
A Sturm-Liouville Problem is a problem that satisfies the following equation with the following boundary conditions,
$$0 = \f{d}{dx}\l[p(x)\f{dy}{dx}\r]-q(x)y+\la r(x)y$$
Alternately,
$$0 = \f{dy}{dx}\f{d}{dx}\l[p(x)\r] + p(x)\f{d^2y}{dx^2}-q(x)y+\la r(x)y$$
$$0 = p(x)\f{d^2y}{dx^2} + p'(x)\f{dy}{dx}-q(x)y+\la r(x)y$$
The initial conditions are shown below,
$$0 = \a_1y(a) - \a_2y'(a)\quad,\quad 0 = \be_1y(b) + \be_2y'(b)$$
wherein neither $\a_1$ and $\a_2$ both zero nor $\be_1$ and $\be_2$ both zero. The parameter $\la$ is the eigenvalue whose possible (constant) values are sought usually via the application of the boundary conditions.
%Seperator
%Seperator
\subsection{Eigenvalue Theorem of Sturm-Liouville Problems}
Suppose that the functions $p(x)$, $p'(x)$, $q(x)$ and $r(x)$ are continuous
on the closed interval $[a,b]$ and that $p(x)>0$ and $r(x)>0$ at each point of $[a,b]$. Then the eigenvalues of the SturmLiouville problem constitute an increasing sequence,
$$\la_1 < \la_2 < \la_3 < \dots <\la_\infty$$
of real numbers with
$$\lim_{n\to\infty}[\la_n] = \infty$$
To within a constant factor, only a single eigenfunction $y_n(x)$ is associated with each eigenvalue $\la_n$. Moreover, if $q(x)\geq0$ on the closed interval $[a,b]$ and the coefficients $\a_1$, $\a_2$, $\be_1$, and $\be_2$ are all non-negative, then the eigenvalues are all non-negative.
%Seperator
%Seperator
\subsection{Eigenvalues-Eigenfunctions Series}
If the functions $p(x)$, $q(x)$ and $r(x)$ of the Sturm-Liouville problem satisifes the Eigenvalue Theorem, then eigenfunctions $y_i(x)$ and $y_j(x)$ corresponding to eigenvalues $\la_i$ and $\la_j$ wherein $j\neq1$ are orthogonal with respect to each other relative to the function $r(x)$,
$$0 = \int^{b}_{a}y_i(x)y_j(x)r(x)dx$$
For a sturm-liouville problem with infinite eigenvalues, it is possible to represent an arbitrary function $f(x)$ as the infinite sum of the eigenvalues,
$$f(x) = \sum^{\infty}_{m=1}\l[c_my_m(x)\r]$$
wherein $y_m(x)$ represents the $m^{th}$ eigenfunction of the $m^{th}$ eigenvalue $\la_m$. Taking the integral in both sides with the product to the eigenfunction $y_n(x)$ relative to the function $r(x)$,
$$\int^{b}_{a}f(x)y_n(x)r(x)dx = \int^{b}_{a}\sum^{\infty}_{m=1}\l[c_my_m(x)\r]y_n(x)r(x)dx$$
Using the assumption, $\dst{0 = \int^{b}_{a}y_i(x)y_j(x)r(x)dx}$,
$$\int^{b}_{a}f(x)y_n(x)r(x)dx = \int^{b}_{a}c_n\l[y_n(x)\r]^2r(x)dx = c_n\int^{b}_{a}\l[y_n(x)\r]^2r(x)dx$$
Therefore, the constant $c_n$ could be obtained by,
$$c_n = \f{\dst{\int^{b}_{a}f(x)y_n(x)r(x)dx}}{\dst{\int^{b}_{a}\l[y_n(x)\r]^2r(x)dx}}$$
This particular theorem could be used to prove under certain reasonable conditions that there exists an infinite series that would allow the boundary conditions to be implemented analytically into the partial differential equations problems.
%Seperator
%Seperator
%Seperator
%Physics Archives
\section{Temperature Distribution of a Heated Rod}
\begin{comment}
Havent inserted Sturm Liouville orthonormal basis functions
\end{comment}
The function of temperature $u$ at some distance $x$ from the origin of a one-dimensional heated rod of uniform material is governed by the equation below,
$$\f{\p u}{\p t} = k\f{\p^2 u}{\p x^2}$$
wherein $k$ is some constant related to thermal conductivity. Using the substitution, $u(x,t) = f(x)g(t)$ wherein $f(x)$ is a function purely in $x$ and $g(t)$ is a function purely in terms of $t$,
$$\f{\p [f(x)g(t)]}{\p t} = k\f{\p^2 [f(x)g(t)]}{\p x^2}$$
$$f(x)\f{\p [g(t)]}{\p t} = kg(t)\f{\p^2 [f(x)]}{\p x^2}$$
$$f(x)g'(t) = kg(t)f''(x)$$
wherein $g'(t)$ represents the first order derivative of $g(t)$ with respect to time $t$, and $f''(x)$ represents second order derivative of $f(x)$ with respect to distance $x$. Further manipulation to yield a left hand side completely in terms of time $t$ and a right hand side completely in terms of displacement $x$,
$$\f{1}{k}\f{g'(t)}{g(t)} = \f{f''(x)}{f(x)} = \lambda$$
wherein $\lambda$ is some constant. The reason why $\lambda$ is a constant is because $x$ and $t$ are independent variables, therefore a change in one of the values should not affect the other variable. Since the left hand side is and right hand side are in represented completely in independent variables, $\lambda$ must be a constant if $x$ and $t$ are independent variables. $\la$ is the eigenvalue of the problem whose values are often sought and is inferred from the boundary conditions. This is as far as analysis can go without specifying the boundary conditions.
\subsection{Zero-Endpoint Temperatures}
Suppose the rod is of length $L$ and that the initial temperature distribution is known. The boundary conditions,
$$u(0,t) = u(L,t) = 0\quad,\quad u(x,0) = m(x)$$
The first boundary condition is the zero endpoint condition and the second condition is the initial temperature distribution. Reiterating the first boundary condition and substituting $u(x,t)$ as the product of two single variable functions,
$$u(0,t) = u(L,t) = 0\quad,\quad f(0)g(t) = f(L)g(t) = 0$$
The function $g(t)$ is not trivial, and therefore, $g(t) \neq 0$. Therefore, it follows that,
$$f(0) = f(L) = 0$$
Because the endpoint conditions, it is convenient that the function $f(x)$ be made into a trigonometric function. Consider the eigenvalue to be negative,
$$\f{1}{k}\f{g'(t)}{g(t)} = \f{f''(x)}{f(x)} = -\lambda$$
Two ordinary differential equation problems can be obtained from this,
$$\f{1}{k}\f{g'(t)}{g(t)} = -\lambda \quad,\quad \f{f''(x)}{f(x)} = -\lambda$$
$$g'(t) = -\lambda kg(t) \quad,\quad f''(x) = -\lambda f(x)$$
The second ordinary differential equation, $\dst{f''(x) = -\lambda f(x)}$ has the solution, 
$$f(x) = c_1\cos\l(\sqrt{\la}x\r) + c_2\sin\l(\sqrt{\la}x\r)$$
To satisfy the endpoint condition $\dst{f(0) = f(L) = 0}$, $c_1 = 0$ and $\sqrt{\la}L = n\pi$, wherein $n$ are integers starting from zero. Therefore, $\la = n^2\pi^2/L^2$. Substituting the eigenvalues and arbitrary constants $c_1$,
$$f(x) = c_2\sin\l(\f{n\pi}{L} x\r)$$
Substituting the eigenvalue and solving the second ordinary differential equations problem,
$$g'(t) = -\f{n^2\pi^2k}{L^2}g(t)$$
$$\int\f{1}{g(t)}dg(t) = -\f{n^2\pi^2k}{L^2}\int dt$$
$$\ln[g(t)] = -\f{n^2\pi^2k}{L^2}t + c$$
$$g(t) = Ce^{\dst{-\l(\f{n^2\pi^2k}{L^2}\r)t}}$$
Substituting the two equations together,
$$u(x,t) = C_ne^{\dst{-\l(\f{n^2\pi^2k}{L^2}\r)t}}\sin\l(\f{n\pi}{L} x\r)$$
Due to the partial differential operator being a linear operator, the superposition principle holds true. Therefore, the general solution to the partial differential equation must be the linear combination of its linearly independent solutions,
$$u_g(x,t) = \sum^{\infty}_{n=1}\l[C_ne^{\dst{-\l(\f{n^2\pi^2k}{L^2}\r)t}}\sin\l(\f{n\pi}{L} x\r)\r]$$
\subsection{Insulated Ends}
With the same length of rod $L$ and known initial temperature distribution $m(x)$, the boundary conditions,
$$\f{\p}{\p x}\l[u(0,t)\r] = \f{\p}{\p x}\l[u(L,t)\r] = 0\quad,\quad u(x,0) = m(x)$$
Substituting the boundary conditions with the definition of $u$ as the product of two single variable functions,
$$f'(0)g(t) = f'(L)g(t) = 0$$
Similarly to the previous case, since $g(t)$ is not the trivial zero function,
$$f'(0) = f'(L) = 0$$
Just in the previous part, it is convenient to choose the eigenvalues to be negative in the two ordinary differential equation problems,
$$\f{1}{k}\f{g'(t)}{g(t)} = -\lambda \quad,\quad \f{f''(x)}{f(x)} = -\lambda$$
This is advantageous because $f$ will take the form of a linear combination of trigonometric functions, at which we can simply choose the cosine series to satisfy the boundary condition above. The general form of $f(x)$,
$$f(x) = c_1\cos\l(\sqrt{\la}x\r) + c_2\sin\l(\sqrt{\la}x\r)$$
$$f'(x) = -c_1\sin\l(\sqrt{\la}x\r) + c_2\cos\l(\sqrt{\la}x\r)$$
The only conditions that would satisfy the end-point boundary conditions, $c_2 = 0$, $\sqrt{\la}L = n\pi$, $\la = n^2\pi^2/L^2$. Substituting the eigenvalues and arbitrary constants would yield,
$$f(x) = c_1\cos\l(\f{n\pi}{L}x\r)$$
Solving for $g(t)$ yields,
$$g'(t) = -\la k g(t)$$
Familiarly,
$$g(t) =  e^{-\la k t} = Ce^{\dst{\l(-\f{n^2\pi^2k}{L^2} t\r)}}$$
Similarly to the previous section and by principle of superposition,
$$u_g(x,t) = \sum^{\infty}_{n=1}\l[C_ne^{\dst{-\l(\f{n^2\pi^2k}{L^2}\r)t}}\cos\l(\f{n\pi}{L} x\r)\r]$$
%Seperator
%Seperator
%Seperator
%Physics Archives
\section{One-Dimensional Wave Equation}
\begin{comment}
\end{comment}
The equation for the one-dimensional wave equation is shown below,
$$\f{\p^2 y}{\p t^2} = a^2\f{\p^2 y}{\p x^2}$$ 
Using the familiar substitution $\dst{y(x,t) = u(x)\times r(t)}$,
$$\f{\p^2}{\p t^2}\l[u(x)r(t)\r] = a^2\f{\p^2}{\p x^2}\l[u(x)r(t)\r]$$ 
$$u(x)r''(t) = a^2u''(x)r(t)$$ 
wherein $r''(t)$ and $u''(x)$ represents the second order derivative of $r(t)$ and $u(x)$ respectively. Manipulation of the equation,
$$\f{1}{a^2}\f{r''(t)}{r(t)} = \f{u''(x)}{u(x)}$$
To fit for the somewhat arbitrary conditions,
$$y(0,t) = y(L,t) = 0\quad,\quad y(x,0) = f(x) \quad,\quad \f{\p}{\p t}\l[y(x,0)\r] = g(x)$$
it is useful to consider the derivative homogenous case (A) and the displacement homogenous case (B) seperately,
$$y_A(0,t) = y_A(L,t) = 0\quad,\quad y_B(0,t) = y_B(L,t) = 0$$
$$y_A(x,0) = f(x)\quad,\quad y_B(x,0) = 0$$
$$\f{\p }{\p t}[y_A(x,0)] = 0\quad,\quad \f{\p }{\p t}[y_B(x,0)] = g(x)$$
The somewhat arbitray boundary condition case would be the satisfied by the  addition of the derivative homogenous case  and the displacement homogenous case. Both function $y_A(x,t)$ and $y_B(x,t)$ satisifes the partial differential equation, therefore, the algebraic addition of them must also satisfy the one dimensional wave equation. When they are added algebraically,
$$y_A(0,t) + y_B(0,t) = y_A(L,t) + y_B(L,t) = 0 + 0$$
$$y_A(x,0) + y_B(x,0) = f(x) + 0\quad,\quad \f{\p}{\p t}\l[y_A(x,0) + y_B(x,0)\r] = 0 + g(x)$$
Therefore, the algebraic addition of the derivative homogenou and displacement homogenous satisfies the somewhat arbitrary conditions provided earlier.
%Seperator
%Seperator
\subsection{Derivative Homogenous Case}
The boundary conditions for the derivative homogenous case,
$$y(0,t) = y(L,t) = 0\quad,\quad y(x,0) = f(x)\quad,\quad\f{\p }{\p t}[y(x,0)] = 0$$
To satisfy the first boundary condition listed above, it would be convenient for the eigenvalues to be considered negative,
$$\f{1}{a^2}\f{r''(t)}{r(t)} = \f{u''(x)}{u(x)} = -\la$$
Therefore, the two ordinary differential equations,
$$u''(x) = -\la u(x)\quad,\quad r''(t) = -\la a^2 r(t)$$
The characteristic equation associated to the displacement differential equation,
$$r^2 = -\la\quad,\quad r = \sqrt{\la}i$$
Therefore, the displacement function $u(x)$ is in terms of the familiar linear combination of trigonometric functions,
$$u(x) = c_1\cos\l(\sqrt{\la}x\r) + c_2\sin\l(\sqrt{\la}x\r)$$
The only constants that will satisfy the condition $\dst{y(0,t) = y(L,t) = 0}$, $c_1 = 0$, and $\sqrt{\la}L = n\pi$. Therefore, the eigenvalues are, $\dst{\la = \f{n^2\pi^2}{L^2}}$. Substituting for eigenvalues and arbitray constant $c_1$ into $u(x)$,
$$u(x) = c_2\sin\l(\f{n\pi}{L}x\r)$$
The characteristic equation associated to the time dependent differential equation,
$$r^2 = -\la a^2\quad,\quad r = a\sqrt{\la}i$$
Therefore, the trigonometric solution to the above characteristic equation,
$$r(t) = k_1\cos\l(a\sqrt{\la}t\r) + k_2\sin\l(a\sqrt{\la}t\r)$$
$$r(t) = k_1\cos\l(\f{n\pi a}{L}t\r) + k_2\sin\l(\f{n\pi a}{L}t\r)$$
%Seperator
%Seperator
\subsection{Displacement Homogenous Case}
The boundary conditions for the displacement homogenous case,
$$y(0,t) = y(L,t) = 0\quad,\quad y(x,0) = 0\quad,\quad\f{\p }{\p t}[y(x,0)] = g(x)$$
%Seperator
%Seperator
%Seperator
\end{center}
\end{document}

\grid
